from geographiclib.geodesic import Geodesic
import firebase_admin
from firebase_admin import credentials, firestore
from firebase_admin import credentials, db
from PySide6.QtQml import QQmlApplicationEngine
from PySide6.QtWidgets import QApplication
from pathlib import Path
import sys
from datetime import datetime
import threading
from difflib import SequenceMatcher
from pywinauto import application
import math
from pynput import mouse, keyboard
import re
import os
import time
import numpy as np
import pyautogui
import pytesseract
import cv2
from PIL import ImageGrab
from OpenGL.GLU import *
from OpenGL.GL import *
import psutil
from PySide6.QtGui import QSurfaceFormat
from PySide6.QtCore import QObject, Slot
from geopy.geocoders import Nominatim
# Android
from plyer import gps
from kivy.clock import Clock
from kivy.utils import platform


def on_location(**kwargs):
    print(
        kwargs['lat'],
        kwargs['lon'],
        kwargs.get('altitude'),
        kwargs.get('speed')
    )


gps.configure(on_location=on_location)
gps.start(minTime=1000, minDistance=0)

if platform == 'android':
    from plyer import accelerometer
    accelerometer.enable()


def read_imu(dt):
    val = accelerometer.acceleration
    if val:
        ax, ay, az = val
        print(ax, ay, az)


Clock.schedule_interval(read_imu, 1/50)

# --- åŸºç¤è¨­å®š --- python "D:\Python\Non-codeAutomaticOperation\UIA.py"
pytesseract.pytesseract.tesseract_cmd = r"C:\Users\USER\AppData\Local\Programs\Tesseract-OCR\tesseract.exe"
base_path = getattr(sys, '_MEIPASS', os.path.dirname(
    os.path.abspath(__file__)))
TEMPLATE_DIRS = {
    "live_capture": os.path.join(base_path, 'live_capture'),
    "attributes": os.path.join(base_path, "attributes"),
    "world": os.path.join(base_path, "world"),
    "communication": os.path.join(base_path, "communication"),
    "dark_matter": os.path.join(base_path, "dark_matter"),
    "thinking": os.path.join(base_path, "thinking"),  # ä¸­è½‰ç«™
    "thinking2": os.path.join(base_path, "thinking2"),  # ä¸­è½‰ç«™
}
MATCH_THRESHOLD = 0.85
LANGS = "eng+chi_sim"
DEBUG = True

# --- å…±ç”¨å·¥å…· ---
alive_event = threading.Event()
cred = credentials.Certificate("serviceAccountKey.json")
firebase_admin.initialize_app(cred, {
    "databaseURL": "https://ä½ çš„å°ˆæ¡ˆ-id.firebaseio.com/"
})


def watchdog():
    while not alive_event.wait(timeout=10):
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        cv2.imwrite(f"debug_{ts}.png", screenshot())
        print(f"[Watchdog] ä¸»ç·šç¨‹å¯èƒ½å¡æ­»ï¼Œå·²ä¿å­˜ debug_{ts}.png")


def screenshot():
    """æˆªå–å…¨å±ä¸¦è½‰æˆOpenCVåœ–åƒ  RGB â†’ BGR """
    img = np.array(ImageGrab.grab())
    return cv2.cvtColor(img, cv2.COLOR_RGB2BGR)


def locate_template_orb(name, sort=1, num=1, extractor=False, dir=TEMPLATE_DIRS["img"]):
    """ORB ç‰¹å¾µåŒ¹é…æ‰¾åœ–åƒ screenshot() â†’ ç°éš """
    name = name.split("<img>")[1]
    path = os.path.join(dir, f"{name}.png")
    if not os.path.exists(path):
        return None
    tpl = cv2.imread(path, 0)
    screen_gray = cv2.cvtColor(screenshot(), cv2.COLOR_BGR2GRAY)
    # å¯èª¿æ•´ç‰¹å¾µæ•¸ï¼Œè¶Šå°‘è¶Šå¿«ï¼Œ100å°åœ–æ¨™æˆ–æŒ‰éˆ•ã€300ä¸€èˆ¬GUIå…ƒç´ ã€500è¤‡é›œç•«é¢(ä¾‹å¦‚ Hierarchy)
    orb = cv2.ORB_create(400)
    kp1, des1 = orb.detectAndCompute(tpl, None)
    kp2, des2 = orb.detectAndCompute(screen_gray, None)
    if des1 is None or des2 is None:
        return None
    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
    matches = sorted(bf.match(des1, des2), key=lambda m: m.distance)
    if len(matches) < 5:
        return None  # å¤ªå°‘ç‰¹å¾µé…å°è¦–ç‚ºä¸å¯é 
    # å–å‰ 10 å€‹æœ€ä½³åŒ¹é…é»çš„åº§æ¨™
    pts = [(int(kp2[m.trainIdx].pt[0]), int(kp2[m.trainIdx].pt[1]))
           for m in matches[:10]]
    pts.sort(key=lambda p: (p[0], p[1]))  # å·¦ä¸Šæ’åº
    if not pts:
        TargetExtractor().select_polygon_roi()

    # é¸å–é»
    if sort == "å¥‡æ•¸":
        pts = pts[::2]
    elif sort == "å¶æ•¸":
        pts = pts[1::2]
    elif isinstance(sort, int):
        idx = sort - 1 if sort > 0 else sort
        return [pts[idx]] if -len(pts) <= idx < len(pts) else []
    # è™•ç† num(æ­£æ•¸å–å‰ numï¼Œè² æ•¸å–å€’æ•¸ abs(num)ï¼‰
    if num != 1:
        pts = pts[:num] if num > 0 else pts[num:]
    return pts

# *** å¤šå¼µåœ–åƒä¸­åµæ¸¬ç›®æ¨™åœ–åƒ


def locate_template_orb_cached(obj, name, sort=1, num=1):
    if name in obj.cache:
        pos = obj.cache[name]
        if validate_cache(name, pos):
            return pos
    pos = locate_template_orb(name, sort, num, extractor=obj.extractor)
    if pos:
        obj.cache[name] = pos
    return pos


def validate_cache(name, pos, tolerance=10, dir=TEMPLATE_DIRS["img"]):
    screen_gray = cv2.cvtColor(screenshot(), cv2.COLOR_BGR2GRAY)
    h, w = screen_gray.shape[:2]
    x, y = pos
    # å®‰å…¨é‚Šç•Œ
    x1, y1 = max(x - tolerance, 0), max(y - tolerance, 0)
    x2, y2 = min(x + tolerance, w), min(y + tolerance, h)
    region = screen_gray[y1:y2, x1:x2]
    tpl = cv2.imread(os.path.join(dir, f"{name}.png"), 0)
    if tpl is None or region.size == 0:
        return False
    res = cv2.matchTemplate(region, tpl, cv2.TM_CCOEFF_NORMED)
    _, max_val, _, _ = cv2.minMaxLoc(res)
    return max_val > 0.8


def locate_text(keyword, sort=1, num=1, classA=None):
    """æ‰¾å­—"""
    # OCRè­˜åˆ¥æ–‡å­—
    data = pytesseract.image_to_data(cv2.cvtColor(screenshot(
    ), cv2.COLOR_BGR2GRAY), lang=LANGS, output_type=pytesseract.Output.DICT)
    # æ”¶é›†åŒ¹é…é»
    pts = [
        (data['left'][i] + data['width'][i] // 2,
         data['top'][i] + data['height'][i] // 2)
        for i, t in enumerate(data['text'])
        # SequenceMatcher ç›¸ç¬¦æ¯”ä¾‹
        if t.strip() and SequenceMatcher(None, t.lower(), keyword.lower()).ratio() >= 0.7
    ]
    if not pts:
        if DEBUG:
            print(f"âš ï¸ æ‰¾ä¸åˆ°åŒ¹é…é»ï¼š{keyword}ã€‚è‹¥ç›®æ¨™åœ¨å ´å‰‡å»ºè­°")
        return None
    # æ’åº(å·¦ä¸Šå„ªå…ˆï¼‰
    pts.sort(key=lambda p: (p[0], p[1]))
    # sort æ•´æ•¸ â†’ æŒ‡å®šä½ç½®ï¼›å¥‡å¶ â†’ ç¯©é¸ï¼›å¦å‰‡å›å‚³å‰ num å€‹ # åºåˆ—[start:end:step]
    if sort == "å¥‡æ•¸":
        pts = pts[::2]
    elif sort == "å¶æ•¸":
        pts = pts[1::2]
    elif isinstance(sort, int):
        idx = sort - 1 if sort > 0 else sort
        return pts[idx] if -len(pts) <= idx < len(pts) else None
    # è™•ç† num(æ­£æ•¸å–å‰ numï¼Œè² æ•¸å–å€’æ•¸ abs(num)ï¼‰
    if num != 1:
        pts = pts[:num] if num > 0 else pts[num:]
    if classA is None:
        return pts
    else:
        # * æ‰¾classA çš„å…§å®¹ï¼Œé è¨­æ˜¯ # æ‰¾ classA çš„é€™ä¸€è¡Œ classAå¾Œé¢
        readText = [
            t
            for t in data['text']
            if t.strip() and SequenceMatcher(None, t.lower(), keyword.lower()).ratio() >= 0.7
        ]

        # *** classA ä¼¼ä¹åœ¨é€™ä¸€è¡Œé–‹å§‹ä¸é€šç”¨äº†ï¼Œä½¿ç”¨åˆ° Geocoding
        # *** firebase ç”¨æˆ¶å„²å­˜çš„èµ·é»åœ°å€ addrStart
        geolocator = Nominatim(user_agent="geo_example")
        startP = firestore.client("ç”¨æˆ¶").reference("addrStart").get()
        nearP = firestore.client("ç”¨æˆ¶").document("near").get().to_dict()
        farP = firestore.client("ç”¨æˆ¶").document("far").get().to_dict()
        locationStart = geolocator.geocode(startP)
        locationNear = geolocator.geocode(startP)
        locationFar = geolocator.geocode(startP)
        # é–“è·å¤ªè¿‘(firestore.client().reference(å¤ªè¿‘çš„åœ°å€)ï¼Œèµ·é»å’Œå¤ªè¿‘åœ°å€çš„è·é›¢ç‚º é–“è·)çš„ä¸€äº›åœ°å€ç‚ºä¸€åˆ†æ”¯ manifest[åˆ†æ”¯]ï¼Œé›¢èµ·é»å¤ªé (firestore å¤ªé åœ°å€)é¡å¤–å®‰æ’ manifest2
        NEAR_DISTANCE = dist(nearP, startP)
        FAR_DISTANCE = dist(farP, startP)

        def dist(a, b):
            aLocation = geolocator.geocode(a)
            # é¿å…è¢«geocode å°é–
            time.sleep(0.5)
            if b == startP:
                bLocation = locationStart
            elif b == nearP:
                bLocation = locationNear
            elif b == farP:
                bLocation = locationFar
            else:
                bLocation = geolocator.geocode(b)
            if aLocation or bLocation is None:
                print("ç„¡æ•ˆåœ°å€")
            distance = (aLocation.latitude - bLocation.latitude)**2 + \
                        (aLocation.longitude - bLocation.longitude)**2
            time.sleep(0.5)
            return distance

        for ress in readText:
            line_key = (
                data['block_num'][ress],
                data['par_num'][ress],
                data['line_num'][ress]
            )
            addresses = []
            for j, t in enumerate(data['text']):
                if not t.strip():
                    continue
                if j < ress:
                    continue
                if (data['block_num'][j], data['par_num'][j], data['line_num'][j]) != line_key:
                    continue

                addresses.append({
                    "address": t,
                    "distance": dist(t, startP),
                    # ***ä½¿ç”¨ æ‰¾åœ°å€æ™‚ï¼Œé †ä¾¿ æ‰¾è²¨å“
                    # *** æœå°‹ç›¸ç¬¦æ–‡å­—çš„è²¨å“ä¹˜ä¸Šæ•¸é‡ï¼Œä¸¦è¨ˆç®—ç–ŠåŠ çš„ç©ºé–“å¤§å°ï¼Œä»¥ç–ŠåŠ å¤§å°ä¾†æ’åº
                    "goods": ""
                })
            addresses.sort(key=lambda x: x["distance"])
            # å»ºç«‹ manifest åˆ†æ”¯(è¿‘ / é ï¼‰ # ç”¨æˆ¶èªªåˆ†æ”¯ï¼Œä¹Ÿæœ‰å¯èƒ½æ˜¯èªªå…¶ä»–æ±è¥¿
            manifest_near = [
                {"address": addresses[i]["address"],
                    "goods": addresses[i]["goods"]}
                for i in range(len(addresses)-1)  # ç”¨ index æ‰èƒ½æ‹¿ä¸‹ä¸€ç­†
                if addresses[i]["distance"] <= NEAR_DISTANCE
                and abs(addresses[i]["distance"] - addresses[i+1]["distance"]) <= NEAR_DISTANCE
            ]
            manifest_far = [
                {"address": info["address"], "goods": info["goods"]}
                for info in addresses
                if info["distance"] >= FAR_DISTANCE
            ]
            manifest = [manifest_near, manifest_far]
            # *** goods æ’åˆ—åœ¨æœ‰é™ç©ºé–“ï¼Œè¨ˆç®—manifesté›£åº¦ æ’åº
            # 4ï¸âƒ£ ä¸Šå‚³ Firebase
            # manifest ä¸Šå‚³çµ¦firebaseï¼Œmanifestä¸­æœ€é›£çš„çµ¦æœ€æ—©è«‹æ±‚çš„ç”¨æˆ¶ # *** firebase åˆ†ç™¼çµ¦ç”¨æˆ¶ï¼Œç”¨æˆ¶å¦‚ä½•ç²å– manifest

            firestore.client().document("manifest").add(manifest)

                # *** ç¹ªè£½è·¯ç·šåœ–ä¸¦è¨˜éŒ„æŒ‡å—é‡æ–¹å‘ï¼Œæ—‹è½‰åœ°åœ–æ™‚è·¯ç·šåœ–èˆ‡åœ°åœ–çš„æŒ‡å—é‡å‘é‡ çŸ¯æ­£
                # *** æŒ‡å—é‡è¨ˆç®—(ä¸€ç¶­)
                # Routing APIçµ¦æœ€ä½³çœŸå¯¦è·¯ç·š


def click(pos): pyautogui.moveTo(
    *pos, duration=0.2); pyautogui.click(); time.sleep(0.3)


class InputCommand(QObject):
    def __init__(self):
        super().__init__()
        self.vars = {}
        self.current_window = None
        self.cache = {}
        self.extractor = True
        self.app = None

    def focus_window(self, title):
        title_pattern = fr'^{title}.*'
        try:
            app = application(backend="uia").connect(title_re=title_pattern)
            app.window(title_re=title_pattern).set_focus()
            self.current_window = title
            print(f"ğŸ§  èšç„¦ [{title}]")
        except Exception as e:
            print(f"âŒ ç„¡æ³•èšç„¦ [{title}]: {e}")

    def selected(self, str, sort=1, num=1, classA=None):
        if "<img>" in str:
            return locate_template_orb_cached(str, sort, num)
        else:
            return locate_text(str, sort, num, classA)

    @Slot(str)
    def input_line(self, user_input):
        m = re.match(r"<\s*(.+)\s*>", user_input)
        if m:
            cmd_type = m.group(1).strip()
            match cmd_type:
                case "éŒ„è£½":
                    raw = input("è«‹è¼¸å…¥è¦éŒ„è£½çš„å‘½ä»¤(å¤šè¡Œç”¨::åˆ†éš”): ").strip()
                    rec.record(raw)
                case "æ’­æ”¾":
                    var = input("æ’­æ”¾å“ªå€‹éŒ„è£½è®Šæ•¸: ").strip() or None
                    rec.play(ic, var)
                case "æª¢è¦–éŒ„è£½":
                    rec.view()
                case "é‡æ–°å‘½å":
                    old_name = input("åŸè®Šæ•¸å: ").strip()
                    new_name = input("æ–°è®Šæ•¸å: ").strip()
                    rec.rename(old_name, new_name)
                case "å–æ¶ˆè‡ªå‹•ç¢ºèªç›®æ¨™":
                    ic.extractor = False
                    print("âœ… å·²é—œé–‰è‡ªå‹•ç¢ºèªç›®æ¨™æ¨¡å¼")
                case "ç§»é™¤":
                    var = input("ç§»é™¤å“ªå€‹éŒ„è£½è®Šæ•¸: ").strip() or None
                    rec.remove(ic, var)
                case "æ•´ç†è·¯ç·š":  # ***æ•´ç†è·¯ç·š
                    var = input("å·²é–‹å•Ÿ æ•´ç†è·¯ç·š ").strip() or None
                    self.selected("åœ°å€", 1, 1, "åœ°å€")

                case "è·é›¢å¤šå°‘":  # ***å’Œä¸‹ä¸€å€‹åœ°å€ è·é›¢å¤šå°‘
                    var = input("å·²ç¹ªè£½åœ°åœ– ").strip() or None

                    def real_dist(p, q):
                        return Geodesic.WGS84.Inverse(
                            p.lat, p.lon, q.lat, q.lon
                        )['s12']
                case "ç¹ªåœ–":  # ***ç¹ªåœ–
                    var = input("å·²ç¹ªè£½åœ°åœ– ").strip() or None

                case _:
                    print(f"âš ï¸ æœªçŸ¥æŒ‡ä»¤: {cmd_type}")
        else:
            # æ™®é€šå‘½ä»¤ç›´æ¥åŸ·è¡Œ
            cmds = user_input.split("::")
            ic.execute_line(cmds)

    def execute_line(self, lines):
        for line in lines:
            try:
                window, path, action = [x.strip() for x in line.split(',', 2)]
                if self.current_window != window:
                    self.focus_window(window)
                    time.sleep(0.5)
                # *éµç›¤æ»‘é¼ 
                # -*- coding: utf-8 -*- # æ»‘é¼  + éµç›¤å…¨åŠŸèƒ½ç¤ºä¾‹(ä¸å«ç›£è½ï¼‰ import pyautogui, keyboard, time from pynput.mouse import Button, Controller as MouseController from pynput.keyboard import Key, Controller as KeyController # pyautogui å…¨åŸŸè¨­å®š pyautogui.FAILSAFE = True pyautogui.PAUSE = 0.1 # ==== æ»‘é¼ æ§åˆ¶ ==== # ä½ç½®è³‡è¨Š screen_w, screen_h = pyautogui.size() print("Screen:", screen_w, screen_h) print("Mouse position:", pyautogui.position()) # åŸºæœ¬ç§»å‹• pyautogui.moveTo(100, 100, duration=0.3) pyautogui.moveRel(50, 0, duration=0.2) # é»æ“Šèˆ‡é›™æ“Š pyautogui.click() pyautogui.doubleClick() pyautogui.rightClick() pyautogui.middleClick() pyautogui.click(300, 300) # æŒ‰ä¸‹ / æ”¾é–‹(å¯é•·æŒ‰ï¼‰ pyautogui.mouseDown(button='left') time.sleep(0.5) pyautogui.mouseUp(button='left') # æ‹–æ›³æ“ä½œ pyautogui.moveTo(400, 400) pyautogui.mouseDown() pyautogui.moveTo(600, 600, duration=1.0) pyautogui.mouseUp() # æ»¾è¼ª pyautogui.scroll(300) pyautogui.scroll(-300) # ==== éµç›¤æ§åˆ¶ ==== # è¼¸å…¥æ–‡å­— pyautogui.typewrite("Hello from pyautogui!", interval=0.05) # å–®éµæ“ä½œ pyautogui.press("enter") pyautogui.press("tab") pyautogui.press("backspace") # çµ„åˆéµ pyautogui.hotkey("ctrl", "s") pyautogui.hotkey("alt", "f4") # æ‹†è§£æŒ‰ä¸‹èˆ‡æ”¾é–‹ pyautogui.keyDown("shift") pyautogui.press("a") pyautogui.keyUp("shift") # ==== ä½¿ç”¨ pynput é€²éšæ§åˆ¶ ==== mouse = MouseController() keyboard_ctrl = KeyController() # æ»‘é¼ ç²¾ç¢ºæ§åˆ¶ mouse.position = (200, 200) mouse.press(Button.left) time.sleep(0.3) mouse.release(Button.left) mouse.press(Button.right) mouse.release(Button.right) mouse.scroll(0, 3) # éµç›¤ç²¾ç¢ºæ§åˆ¶ keyboard_ctrl.press('a') keyboard_ctrl.release('a') keyboard_ctrl.press(Key.enter) keyboard_ctrl.release(Key.enter) # ==== ä½¿ç”¨ keyboard æ¨¡çµ„ ==== keyboard.press_and_release('ctrl+c') keyboard.write('Typed by keyboard module!', delay=0.05) if keyboard.is_pressed('esc'): print("ESC pressed!")
                # *é‹ç®—
                # -*- coding: utf-8 -*- import math, random, statistics, decimal, fractions, cmath, numpy as np # === åŸºæœ¬å››å‰‡ === a, b = 10, 3 print(a + b, a - b, a * b, a / b, a // b, a % b, a ** b) # === æ¯”è¼ƒèˆ‡é‚è¼¯ === print(a > b, a < b, a == b, a != b, a >= b, a <= b) # === å…§å»ºå‡½å¼ === print(abs(-5), round(3.14159, 2), pow(2, 5), divmod(17, 3), sum([1,2,3,4])) # === math æ¨¡çµ„ === print(math.sqrt(16), math.pow(2, 10), math.factorial(5)) print(math.sin(math.pi/2), math.cos(0), math.tan(math.pi/4)) print(math.degrees(math.pi), math.radians(180)) print(math.log(100, 10), math.log2(8), math.exp(1)) print(math.ceil(2.1), math.floor(2.9), math.trunc(-3.8)) print(math.gcd(24, 36), math.isclose(0.1+0.2, 0.3)) # === çµ±è¨ˆ === data = [2, 3, 5, 7, 11] print(statistics.mean(data), statistics.median(data), statistics.pstdev(data)) # === éš¨æ©Ÿ === print(random.random(), random.randint(1,10), random.uniform(1.5,5.5)) print(random.choice(['A','B','C'])) items = [1,2,3,4]; random.shuffle(items); print(items) # === decimal é«˜ç²¾åº¦é‹ç®— === decimal.getcontext().prec = 10 x = decimal.Decimal('1.1') + decimal.Decimal('2.2') print(x)  # ç²¾ç¢ºåŠ æ³• # === fractions åˆ†æ•¸ === f1 = fractions.Fraction(1,3); f2 = fractions.Fraction(1,6) print(f1 + f2, f1 * f2) # === è¤‡æ•¸ === z1, z2 = 2+3j, 1-1j print(z1 + z2, z1 * z2, abs(z1), cmath.phase(z1)) # === numpy é«˜éšé‹ç®— === arr = np.array([1,2,3,4,5]) print(arr + 2, arr * 3, np.mean(arr), np.std(arr)) print(np.sin(arr), np.dot([1,2,3],[4,5,6]))
                for pa in path.split(":"):
                    # [(x,y),(x,y),(x,y),...]ï¼Œsp[0]=x,yï¼Œsp[0][1]=yï¼Œæ‰“æ­»GPT
                    sp = self.selected(pa)
                    if sp is not None:
                        if pa != path.split(":")[-1]:
                            click(sp[0])
                        elif pa == path.split(":")[-1]:
                            for act in action.split(":"):
                                i = 0
                                while i < len(action):
                                    act = action[i]
                                    match act:
                                        # Unity
                                        case "é»æ“Š": click(sp[0])
                                        case "é›™æ“Š": pyautogui.doubleClick(sp[0])
                                        case "å³éµ": pyautogui.rightClick(sp[0])
                                        case "ä¸­éµ": pyautogui.middleClick(sp[0])
                                        case "æŒ‰ä¸‹": pyautogui.mouseDown(sp[0])
                                        case "æ”¾é–‹": pyautogui.mouseUp(sp[0])
                                        case "å„²å­˜": pyautogui.hotkey("ctrl", "s")
                                        case "è¤‡è£½": pyautogui.hotkey("ctrl", "c")
                                        case "è²¼ä¸Š": pyautogui.hotkey("ctrl", "v")
                                        case "å…¨é¸": pyautogui.hotkey("ctrl", "a")
                                        case "å‰ªä¸‹": pyautogui.hotkey("ctrl", "x")
                                        case "å¾©åŸ": pyautogui.hotkey("ctrl", "z")
                                        case "å–æ¶ˆå¾©åŸ": pyautogui.hotkey("ctrl", "y")
                                        case "åˆªé™¤": pyautogui.press("delete")
                                        case "èšç„¦è©²ç‰©ä»¶": pyautogui.press("f")
                                        case "é—œé–‰è¦–çª—": pyautogui.hotkey("alt", "f4")
                                        case "æ»¾ä¸Š": pyautogui.scroll(300)
                                        case "æ»¾ä¸‹": pyautogui.scroll(-300)
                                        case "å·¦æ»‘":
                                            pyautogui.dragRel(-200,
                                                              0, duration=0.5)
                                        case "å³æ»‘":
                                            pyautogui.dragRel(
                                                200, 0, duration=0.5)
                                        # è¨ˆç®—å‡ºæœ€å·¦é‚Šæœ€ä¸Šé¢çš„ä¾åºçš„ç¬¬Sä½Nå€‹ï¼Œselected(pa)ï¼Œ-3ç‚ºå€’æ•¸ç¬¬ä¸‰ä½
                                        case act if re.fullmatch(r"ç¬¬(-?\d+)ä½(\d+)å€‹", act):
                                            m = re.fullmatch(
                                                r"ç¬¬(-?\d+)ä½(\d+)å€‹", act)
                                            self.selected(
                                                pa, int(m.group(1)), int(m.group(2)))
                                        # è¨ˆç®—å‡ºæœ€å·¦é‚Šæœ€ä¸Šé¢çš„ä¾åºçš„å¶æ•¸å€‹
                                        case act if re.fullmatch(r"å¶æ•¸(\d+)å€‹", act):
                                            m = re.fullmatch(r"å¶æ•¸(\d+)å€‹", act)
                                            self.selected(
                                                pa, "å¶æ•¸", int(m.group(1)))
                                        case act if re.fullmatch(r"å¥‡æ•¸(\d+)å€‹", act):
                                            m = re.fullmatch(r"å¥‡æ•¸(\d+)å€‹", act)
                                            self.selected(
                                                pa, "å¥‡æ•¸", int(m.group(1)))
                                        case act if re.fullmatch(r"æ’åºå„²å­˜çš„(\s+)", act):
                                            m = re.fullmatch(
                                                r"æ’åºå„²å­˜çš„(\s+)", act)  # ***(å°è±¡)æ’åº
                                            a = []+m.group(1)
                                            a.sort()
                                        case act if re.fullmatch(r"è¼¸å…¥\s*(.+)", act):
                                            s = re.fullmatch(r"è¼¸å…¥\s*(.+)", act)
                                            keyboard.write(
                                                s.group(1), delay=0.05)
                                        case act if re.fullmatch(r"çµ„åˆéµ\s*(.+)", act):
                                            m = re.fullmatch(
                                                r"çµ„åˆéµ\s*(.+)", act)
                                            keys = m.group(
                                                1).split()  # ç©ºæ ¼åˆ†é–‹æ¯å€‹æŒ‰éµ
                                            pyautogui.hotkey(*keys)
                                        case act if re.fullmatch(r"ç­‰å¾…(\d+(?:\.\d+)?)ç§’", act):
                                            m = re.fullmatch(
                                                r"ç­‰å¾…(\d+(?:\.\d+)?)ç§’", act)
                                            time.sleep(float(m.group(1)))
                                        case act if re.fullmatch(r"è·é›¢\s*(.+)([<>=]+)(\d+\.?\d*)çµæŸ", act):
                                            # å³æ™‚åº§æ¨™ï¼Œè·é›¢ å°è±¡ æœ‰ å¤šé ï¼Œæœªé”æˆæ™‚ç¹¼çºŒ
                                            m = re.fullmatch(
                                                r"è·é›¢\s*(.+)([<>=]+)(\d+\.?\d*)", act)
                                            distance = math.dist(
                                                sp[0], m.group(1)[0])
                                            if eval(f"{distance:.2f}{m.group(2)}{float(m.group(3))}"):
                                                i += 2  # è·³åˆ°ã€Œä¸‹ä¸‹å€‹ã€act
                                                continue
                                            else:
                                                i += 1  # æ­£å¸¸å¾€ä¸‹
                                                continue
                                        case "é¡¯ç¤ºè©²ç›®æ¨™åº§æ¨™":
                                            print(f"ğŸ“ {pa}: {sp[0]}")
                                        case "é¡¯ç¤ºæ™‚é–“":
                                            print(
                                                f"ğŸ•’ ç¾åœ¨æ™‚é–“ï¼š{time.strftime('%H:%M:%S')}")
                                        case act if re.fullmatch(r"\s*(.+)çš„é‚è¼¯å°\s*(.+)æ€§èƒ½\s*(.+)çµæŸ", act):
                                            # è¨‚é–±äº‹ä»¶ï¼Œç›£è½m1å°m2ã€m2çš„m3 é”æˆæ™‚çµæŸä¸¦å–æ¶ˆè¨‚é–±
                                            # ç›£è½ä¸­çš„äº‹ä»¶ m1å°m2ï¼Œæœ‰ä¿®æ­£éœ€æ±‚å‰‡å›å ±ä½œæ³•ï¼Œç”šè‡³ä½¿ç”¨è€…è£œå……ä½œæ³•
                                            # ç›£è½ä¸­çš„äº‹ä»¶ m2çš„m3ï¼Œç›®å‰æ€§èƒ½ä½æ–¼ç›®æ¨™çš„70%å‰‡å›å ±ä½œæ³•ï¼Œç”šè‡³ä½¿ç”¨è€…è£œå……ä½œæ³•
                                            m = re.fullmatch(
                                                r"\s*(.+)çš„é‚è¼¯å°\s*(.+)æ€§èƒ½\s*(.+)çµæŸ", act)
                                            monitor.subscribe_event(
                                                m.group(1), m.group(2), m.group(3))
                                            # EventMonitor æŒçºŒåŸ·è¡Œ å¾ŒçºŒæŒ‡ä»¤ï¼Œé€™è¡ŒæŒ‡ä»¤å¯ä»¥è·³éäº†
                                            monitor.ic_em = re.search(
                                                fr"{m.group(2)}æ€§èƒ½{m.group(3)}çµæŸ\s*(.+)", action).group(1)
                                            print(
                                                f"å·²è¨»å†Šäº‹ä»¶ç›£è½ {m.group(1)}->{m.group(2)}->{m.group(3)}ï¼Œå¾ŒçºŒæŒ‡ä»¤äº¤ç”± EventMonitor åŸ·è¡Œ {self.ic_em}")
                                            break
                                        case act if re.fullmatch(r"ç§»é™¤\s*(.+)çš„é‚è¼¯å°\s*(.+)æ€§èƒ½\s*(.+)", act):
                                            # å–æ¶ˆç›£è½ä¸­çš„äº‹ä»¶ m1å°m2ã€m2çš„m3
                                            m = re.fullmatch(
                                                r"ç§»é™¤\s*(.+)çš„é‚è¼¯å°\s*(.+)æ€§èƒ½\s*(.+)", act)
                                            monitor.remove_subscription(
                                                m.group(1), m.group(2), m.group(3))
                                        case "æ’åº":
                                            pass
                                        case "é¡¯ç¤ºä½•ç‰©":
                                            pass
                                        case "æ’å®šä»»å‹™":

                                            pass
                                        case "è¨­å®š å³æ™‚è¨ˆç®—ç‰©é«”å¤§å°çš„ éŒ¨å®šç‰©å¤§å°":
                                            # ** æŠ“å–æ¨¡å¼ï¼Œè¨­å®šéŒ¨å®šç‰©
                                            m = re.match(
                                                r"(.*)_W(\d+)_H(\d+)_Z([\d\.]+)", act[i+1])
                                            if not m:
                                                print("è«‹ä¾ç…§åœ–ç‰‡_W0_H0_Z0æ ¼å¼")
                                                return
                                            self.selected(act[i+1])
                                            i += 2
                                            continue
                                        case "å³æ™‚è¨ˆç®—ç‰©é«”å¤§å°":
                                            # *** è¨ˆç®—æ¨¡å¼ï¼Œéœ€è¦OCRè¨ˆç®—ç‰©é«”å®¹ç©
                                            TargetExtractor().load_img_whz()
                                            pass
                                        case "ç•«é¢ç”Ÿæˆæ¨¡å‹":

                                            pass
                                        # ***è£œå……
                                    i += 1  # é è¨­æ¯æ¬¡å¾€ä¸‹ä¸€å€‹
                        # else:æ‰¾ä¸‹ä¸€å€‹è·¯å¾‘
                    else:
                        if pa == path.split(":")[-1]:
                            # æ‰¾æ»‘é¼ é™„è¿‘çš„æœå°‹æ¬„ä½åœ–ç‰‡ï¼Œè¼¸å…¥ç›®æ¨™
                            if self.selected("<img>search") is not None:
                                keyboard.write(pa, delay=0.05)
                            else:
                                print("æ²’è¾¦æ³•æ‰¾åˆ°{pa}")
                        else:
                            # æŒçºŒæ»‘å‹•æª¢æŸ¥å‰ä¸€å€‹è·¯å¾‘çš„æ•´å€‹ç•«é¢ï¼Œç›´åˆ°ç„¡è®ŠåŒ–æ™‚è·³å‡º
                            prev_img = screenshot()
                            while True:
                                if self.selected(pa) is not None:
                                    break
                                pyautogui.scroll(-300)
                                curr_img = screenshot()
                                # æ”¹ç‚ºå·®ç•°çµ±è¨ˆæ³•ï¼Œä¸éœ€æ•´å¼µç•«é¢æ¯”è¼ƒ np.array_equal
                                diff = np.mean(cv2.absdiff(curr_img, prev_img))
                                if diff < 1.0:  # å¯èª¿é–¾å€¼ï¼š<1 ä»£è¡¨å¹¾ä¹æ²’è®Š
                                    print(f"æ²’è¾¦æ³•æ‰¾åˆ° {pa}(ç•«é¢æœªè®ŠåŒ–ï¼‰")
                                # é¿å…é‡ç–Šè¨˜æ†¶é«”å¼•ç”¨
                                prev_img = curr_img.copy()
            except ValueError:
                print("âš ï¸ Invalid format. Please enter: WindowTitle, Path, Action")

    @Slot(str)
    def quitApp(self):
        print("é€€å‡ºæ‡‰ç”¨ç¨‹å¼")
        self.app.quit()


class Recorder:
    def __init__(self):
        # å„²å­˜éŒ„è£½çš„å‘½ä»¤ï¼Œkey:è®Šæ•¸åç¨±ï¼Œvalue:å‘½ä»¤å­—ä¸²
        self.recorded = {}

    def record(self, raw_cmd):
        """éŒ„è£½å‘½ä»¤ï¼Œæ”¯æ´ :: åˆ†å‰²å¤šè¡Œ"""
        lines = raw_cmd.split("::")
        for i, line in enumerate(lines, start=1):
            # é è¨­è®Šæ•¸åï¼šcmd1, cmd2, â€¦
            var_name = f"cmd{i}"
            self.recorded[var_name] = line

    def rename(self, old_name, new_name):
        """é‡æ–°å‘½åå·²éŒ„è£½çš„è®Šæ•¸"""
        if old_name in self.recorded:
            self.recorded[new_name] = self.recorded.pop(old_name)
        else:
            print(f"âš ï¸ {old_name} ä¸å­˜åœ¨")

    def view(self):
        """æª¢è¦–å…¨éƒ¨éŒ„è£½å‘½ä»¤"""
        if not self.recorded:
            print("ğŸ“­ æ²’æœ‰éŒ„è£½å‘½ä»¤")
            return
        for name, cmd in self.recorded.items():
            print(f"{name}: {cmd}")

    def play(self, ic, var_name):
        """åŸ·è¡ŒéŒ„è£½å‘½ä»¤"""
        if var_name not in self.recorded:
            print(f"âš ï¸ {var_name} ä¸å­˜åœ¨")
            return
        cmds = self.recorded[var_name].split("::")
        ic.execute_line(cmds)

    def remove(self, ic, var_name):
        """ç§»é™¤æŒ‡å®šçš„éŒ„è£½å‘½ä»¤"""
        if var_name in self.recorded:
            del self.recorded[var_name]
            print(f"âœ… {var_name} å·²æˆåŠŸç§»é™¤")
        else:
            print(f"âš ï¸ {var_name} ä¸å­˜åœ¨ï¼Œç„¡æ³•ç§»é™¤")


class TargetExtractor:
    def __init__(self, image=None):
        if self.extractor is False:
            print("æ‰¾ä¸åˆ°ç›®æ¨™ä¸”è‡ªå‹•ç¢ºèªæœªé–‹å•Ÿï¼Œè·³éé¸å–é»ã€‚ èª¿æ•´ORB_create>=500")
            return
        else:
            print("#å·²é–‹å•Ÿ æ‰¾ä¸åˆ°ç›®æ¨™å¾Œè‡ªå‹•ç¢ºèªç›®æ¨™")
        self.image = image
        self.base = image.copy()
        self.pts = []
        self.readText = []
        self.done = False
        self.cancelled = False
        self.roi_mask = None
        self.orb = cv2.ORB_create(800)
        self.bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)

    def select_polygon_roi(self):
        """
        å¯è¦–åŒ–äº’å‹•åœˆé¸å¤šé‚Šå½¢ ROI
        - å·¦éµï¼šæ–°å¢é»
        - å³éµï¼šçµæŸåœˆé¸
        - ESCï¼šå–æ¶ˆåœˆé¸
        - Rï¼šé‡ç½®é‡æ–°åœˆ
        """
        print("ğŸ–±ï¸ è«‹ç”¨æ»‘é¼ å·¦éµåœˆé¸å¤šé‚Šå½¢ï¼›å³éµçµæŸï¼›ESC å–æ¶ˆï¼›R é‡ä¾†")
        display = self.image.copy()
        done = False
        # ***å¯èƒ½æœªç›£è½

        def on_click(x, y, button, pressed):
            if not pressed:
                return
            if button == mouse.Button.left:
                self.pts.append((x, y))
                print(f"â• é»({x},{y})")
            elif button == mouse.Button.right:
                if len(self.pts) >= 3:
                    self.done = True
                    print("âœ… çµæŸåœˆé¸")
                else:
                    print("âš ï¸ è‡³å°‘è¦ä¸‰å€‹é»")
                return False

        def on_press(key):
            nonlocal done
            try:
                if key == keyboard.Key.esc:
                    done = True
                    print("âŒ å·²å–æ¶ˆåœˆé¸")
                    return False
                elif key.char.lower() == 'r':
                    print("ğŸ” é‡æ–°åœˆé¸")
                    self.pts.clear()
                    display = self.base.copy()
            except AttributeError:
                pass  # ç‰¹æ®Šéµä¸è™•ç†

        # å•Ÿå‹•ç›£è½
        mouse_listener = mouse.Listener(on_click=on_click)
        key_listener = keyboard.Listener(on_press=on_press)
        mouse_listener.start()
        key_listener.start()
        cv2.namedWindow("Draw ROI", cv2.WINDOW_NORMAL)
        cv2.setWindowProperty("Draw ROI", cv2.WND_PROP_TOPMOST, 1)
        while not self.done and not self.cancelled:
            frame = self.base.copy()
            if len(self.pts) > 1:
                cv2.polylines(frame, [np.array(self.pts)],
                              False, (0, 255, 0), 2)
            for p in self.pts:
                cv2.circle(frame, p, 3, (0, 0, 255), -1)
            cv2.imshow("Draw ROI", frame)
            cv2.waitKey(10)
            if cv2.waitKey(20) & 0xFF == 27:
                break

    def filter_target(self, dir=TEMPLATE_DIRS["img"]):
        """
        å¾ ROI ä¸­æå–ç›®æ¨™ï¼Œåš GrabCut å»èƒŒæ™¯ï¼Œç”Ÿæˆé€æ˜åœ–
        """
        save_path = os.path.join(dir, f"s{time.time():.0f}.png")
        if self.roi_mask is None:
            return None
        # æå–ROIåœ–åƒä¸¦è™•ç†äº®åº¦å°æ¯”
        roi = cv2.bitwise_and(self.image, self.image, mask=self.roi_mask)
        roi_yuv = cv2.cvtColor(roi, cv2.COLOR_BGR2YUV)
        roi_yuv[:, :, 0] = cv2.equalizeHist(roi_yuv[:, :, 0])  # æå‡äº®åº¦å°æ¯”
        roi = cv2.cvtColor(roi_yuv, cv2.COLOR_YUV2BGR)

        # å‰µå»ºåˆå§‹é®ç½©ä¸¦è¨­å®šGrabCutçš„å‰æ™¯/èƒŒæ™¯
        mask = np.zeros(self.image.shape[:2], np.uint8)
        mask[self.roi_mask == 255] = cv2.GC_FGD  # å‰æ™¯
        mask[self.roi_mask == 0] = cv2.GC_BGD    # èƒŒæ™¯

        # GrabCut åˆå§‹åŒ–
        bgdModel = np.zeros((1, 65), np.float64)
        fgdModel = np.zeros((1, 65), np.float64)
        cv2.grabCut(self.image, mask, None, bgdModel,
                    fgdModel, 5, cv2.GC_INIT_WITH_MASK)

        # èª¿æ•´maskï¼Œä½¿å¾—å‰æ™¯èˆ‡å¯èƒ½å‰æ™¯è¦–ç‚ºå‰æ™¯
        mask2 = np.where((mask == cv2.GC_FGD) | (
            mask == cv2.GC_PR_FGD), 255, 0).astype('uint8')

        # å½¢æ…‹å­¸æ¸…ç†(å»å™ªï¼ŒæŸ”é‚Šï¼‰
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        mask2 = cv2.morphologyEx(mask2, cv2.MORPH_OPEN, kernel)  # å»å°å™ªé»
        mask2 = cv2.morphologyEx(mask2, cv2.MORPH_CLOSE, kernel)  # å¡«è£œç©ºæ´
        mask2 = cv2.GaussianBlur(mask2, (5, 5), 0)  # æŸ”é‚Š

        # å»é™¤å°é¢ç©å™ªè²
        num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask2)
        for i in range(1, num_labels):
            if stats[i, cv2.CC_STAT_AREA] < 80:
                mask2[labels == i] = 0

        # åˆä½µåœ–åƒèˆ‡alphaé€šé“(é€æ˜åº¦ï¼‰
        b, g, r = cv2.split(self.image)
        alpha = mask2
        self.extracted = cv2.merge([b, g, r, alpha])

        # å„²å­˜ç‚ºé€æ˜PNG
        os.makedirs(dir, exist_ok=True)  # æ²’æœ‰å°±è‡ªå‹•å»ºç«‹
        cv2.imwrite(save_path, self.extracted)
        print(f"âœ… å·²å„²å­˜ {save_path}")

    # *** ç­‰å¾…QMLè¨­å®š
    # *** Img+GPS åˆ—å‡º åœ–åƒä¸­å æ¯”å¤§çš„ä¸€äº›ç›¸ä¼¼ç‰©é«” å’Œé•·å¯¬é«˜ï¼Œç­‰å¾…QMLè¼¸å…¥è¦å„²å­˜çš„åœ–ç‰‡åç¨±ï¼Œé€²TEMPLATE_DIRS["img"]è³‡æ–™å¤¾ã€‚è¨ˆç®—ç›¸ä¼¼ç‰©å“çš„ å–®ä¸€æ•¸é‡çš„ å¯¦éš›å¤§å°
    def Img_IMU_GPS():
        # è®€å–è¨­å‚™ï¼ŒGPSå¾—é«˜åº¦å°ºå¯ä»¥å’Œåœ°é¢åƒç…§ï¼ŒGPSå¹³ç§»å¾—æ©«å‘å°ºåœ¨ç©ºä¸­è‡³å°‘è¦ç§»å‹•20mï¼Œæ‰å¯ä»¥åƒç…§
        # *** å…ˆæ‹“æ¨¸å¾Œå¹¾ä½•ï¼Œç©©å®šæ‹“æ¨¸çµæ§‹

        # 1ï¸âƒ£ è®€ç›¸æ©Ÿå…§åƒ
        val cameraManager = getSystemService(Context.CAMERA_SERVICE) as CameraManager
        val cameraId = cameraManager.cameraIdList[0]
        val characteristics = cameraManager.getCameraCharacteristics(cameraId)

        val focalLengths = characteristics.get(CameraCharacteristics.LENS_INFO_AVAILABLE_FOCAL_LENGTHS)
        val sensorSize = characteristics.get(CameraCharacteristics.SENSOR_INFO_PHYSICAL_SIZE)

        val fx = focalLengths[0] / sensorSize!!.width * imageWidth
        val fy = focalLengths[0] / sensorSize.height * imageHeight
        val cx = imageWidth / 2f
        val cy = imageHeight / 2f
        val K = arrayOf(arrayOf(fx, 0, cx), arrayOf(0, fy, cy), arrayOf(0, 0, 1))

        # 2ï¸âƒ£ è®€ GPS
        val locationManager = getSystemService(Context.LOCATION_SERVICE) as LocationManager
        val location1 = locationManager.getLastKnownLocation(LocationManager.GPS_PROVIDER)
        val C1 = doubleArrayOf(location1.latitude, location1.longitude, location1.altitude)

        val location2 = locationManager.getLastKnownLocation(LocationManager.GPS_PROVIDER)
        val C2 = doubleArrayOf(location2.latitude, location2.longitude, location2.altitude)

        # 3ï¸âƒ£ æ‹å…©å¼µç…§ç‰‡ï¼Œå–å¾—å½±åƒé» (ORB)
        val orb = ORB.create(3000)
        val kp1 = MatOfKeyPoint()
        val kp2 = MatOfKeyPoint()
        val des1 = Mat()
        val des2 = Mat()
        orb.detectAndCompute(img1, Mat(), kp1, des1)
        orb.detectAndCompute(img2, Mat(), kp2, des2)

        val bf = BFMatcher(NORM_HAMMING, true)
        val matches = bf.match(des1, des2)

        val pts1 = matches.map {kp1.toArray()[it.queryIdx].pt}
        val pts2 = matches.map {kp2.toArray()[it.trainIdx].pt}

        # 4ï¸âƒ£ Essential Matrix + recoverPose (æ—‹è½‰ä¸ç”¨ç®¡)
        val E = Calib3d.findEssentialMat(pts1, pts2, K, RANSAC, 0.999, 1.0)
        val R = Mat()
        val t = Mat()
        Calib3d.recoverPose(E, pts1, pts2, K, R, t)

        # 5ï¸âƒ£ GPS ç•¶å°º
        val baseline = doubleArrayOf(C2[0]-C1[0], C2[1]-C1[1], C2[2]-C1[2])

        # 6ï¸âƒ£ Triangulate
        val P1 = Mat.eye(3, 4, CV_64F)
        val P2 = Mat(3, 4, CV_64F)
        # P2 = [R | -R*t]
        Core.hconcat(listOf(R, -R * Mat(baseline)), P2)

        val pts4D = Mat()
        Calib3d.triangulatePoints(P1, P2, pts1, pts2, pts4D)
        val pts3D = pts4D.rowRange(0, 3) / pts4D.row(3)

        # 7ï¸âƒ£ è¨ˆç®—ç‰©é«”é•·å¯¬é«˜
        val objPts = pts3D.submat(objIndices)
        val sizeX = Core.minMaxLoc(objPts.col(0)).maxVal - Core.minMaxLoc(objPts.col(0)).minVal
        val sizeY = Core.minMaxLoc(objPts.col(1)).maxVal - Core.minMaxLoc(objPts.col(1)).minVal
        val sizeZ = Core.minMaxLoc(objPts.col(2)).maxVal - Core.minMaxLoc(objPts.col(2)).minVal
        println("L,W,H (m): $sizeX, $sizeY, $sizeZ")

        # V2
        // == == = 1ï¸âƒ£ è®€å– GPS == == =
        val locationManager = getSystemService(Context.LOCATION_SERVICE) as LocationManager
        val loc: Location = locationManager.getLastKnownLocation(LocationManager.GPS_PROVIDER)
            ?: return

        val lat = loc.latitude
        val lon = loc.longitude
        val alt = loc.altitude // é«˜åº¦å°º(Zï¼‰
        val speed=loc.speed // m/s

        // == === 2ï¸âƒ£ åˆ¤æ–·æ˜¯å¦åœ¨ç©ºä¸­ == ===
        // å·¥ç¨‹åˆ¤æ–·ï¼šé«˜åº¦ + é€Ÿåº¦(ä¸æ AIï¼‰
        val isAirborne=alt > 20.0 & & speed > 5.0

        // == === 3ï¸âƒ£ è®€å–å½±åƒ == ===
        // img: OpenCV Mat(CameraX / Camera2 è½‰éä¾†ï¼‰
        val img: Mat=currentFrameMat

        // == === 4ï¸âƒ£ æ‰¾ã€Œå¤§å æ¯”ç‰©é«”ã€ == ===
        // ä¸åˆ†é¡ã€ä¸è¿½è¹¤ï¼Œåªæ‰¾æœ€å¤§è¼ªå»“
        val gray=Mat()
        val bin=Mat()
        Imgproc.cvtColor(img, gray, Imgproc.COLOR_BGR2GRAY)
        Imgproc.threshold(gray, bin, 0.0, 255.0,
            Imgproc.THRESH_BINARY + Imgproc.THRESH_OTSU)

        val contours=ArrayList < MatOfPoint > ()
        Imgproc.findContours(
            bin, contours, Mat(),
            Imgproc.RETR_EXTERNAL,
            Imgproc.CHAIN_APPROX_SIMPLE
        )

        if (contours.isEmpty()) return

        val mainContour=contours.maxBy {
            Imgproc.contourArea(it)
        } ?: return

        val rect=Imgproc.boundingRect(mainContour)

        // == === 5ï¸âƒ£ åƒ…åœ¨ã€Œç©ºä¸­ã€æ‰ä½¿ç”¨æ©«å‘å°º == ===
        if (!isAirborne) return

        // == === 6ï¸âƒ£ å°ºåº¦æ›ç®— == ===
        // é«˜åº¦ç›´æ¥ç•¶ Z å°º
        val Z=alt // meters

        // ç›¸æ©Ÿè¦–è§’(ä¾†è‡ªè¨­å‚™ï¼Œå¯¦éš›å¯å¾ CameraCharacteristics è®€ï¼‰
        val hfov=Math.toRadians(60.0) // æ°´å¹³è¦–è§’(ä¾‹ï¼‰
        val vfov=Math.toRadians(45.0)

        val imgW=img.cols().toDouble()
        val imgH=img.rows().toDouble()

        // åƒç´  â†’ å¯¦éš›å°ºå¯¸(å¹¾ä½•ï¼Œä¸æ˜¯ SLAMï¼‰
        val W=2 * Z * Math.tan(hfov / 2) * (rect.width / imgW)
        val H=2 * Z * Math.tan(vfov / 2) * (rect.height / imgH)

        // é•·åº¦ï¼šå–å¯¬é«˜ä¸­è¼ƒå¤§è€…(å·¥ç¨‹å®šç¾©ï¼‰
        val L=maxOf(W, H)

        // == === 7ï¸âƒ£ è¼¸å‡ºå”¯ä¸€çµæœ == ===
        Log.i("SIZE", "L,W,H (m) = $L, $W, $H")


        # *** å„²å­˜3Dæ¨¡å‹


    # *** è®€å–ç•«é¢ä¸­çš„ å·²è¨˜éŒ„çš„ ç‰©å“(åœ–åƒ)ï¼Œå…¨éƒ¨åˆ—å‡ºæˆ–åˆ—å‡ºæŒ‡å®šç‰©å“ï¼Œç„¡ç´€éŒ„çš„åˆ—å‡º


    # ***è®€å–è²¨å“æ¬„çš„ å·²è¨˜éŒ„çš„ ç‰©å“(æ–‡å­—)ï¼Œç„¡ç´€éŒ„çš„åˆ—å‡º
    def load_img_whz(self):
        # *** é™åˆ¶å¤§å°
        whz=[]
        for file in os.listdir(TEMPLATE_DIRS["world"]):
            match=re.match(r"(.*)_W(\d+)_H(\d+)_Z([\d\.]+)\.png", file)
            if not match or not self.selected(file):
                continue
            # ****è®€å–è²¨å“æ¬„çš„ å·²è¨˜éŒ„çš„ ç‰©å“ï¼Œç„¡ç´€éŒ„çš„åˆ—å‡º

            whz.append({
                "obj_name": match.group(1),
                "w": int(match.group(2)),
                "h": int(match.group(3)),
                "z": float(match.group(4))
            })
            # whz.w*whz.h*whz.z
        return whz  # ç–ŠåŠ å¯¦éš›å¤§å°

    # *** python OCRæ‰¾åˆ°è©²ç›®æ¨™æ™‚è¨ˆç®—è©²ç›®æ¨™é™„åœ¨å…¶ç‰©ä¹‹ä¸Šï¼Œåˆ©ç”¨ç›®æ¨™çš„ç‰©ä»¶åç¨±ç´€éŒ„çš„ï¼Œè¨ˆç®—å…¶ç‰©çš„å¯¦éš›å¤§å°
    # *** save_pathåœ–ç‰‡ é‡æ–°å‘½å(å›ºå®šæ ¼å¼æœ‰é•·å¯¬é«˜)ï¼Œåœ¨åˆ¤æ–·ç‰©é«”å¯¦éš›å¤§å°æ¨¡å¼æ™‚ï¼Œåœ¨TEMPLATE_DIRS["img"]ä¸­æ‰¾åˆ°(å›ºå®šæ ¼å¼æœ‰é•·å¯¬é«˜)save_pathåœ–ç‰‡ï¼Œå…¨éƒ¨æ‰¾ä¸€æ¬¡ï¼Œæ‰¾åˆ°å‰‡åˆ†æé™„åœ¨ä½•ç‰©ã€è¨ˆç®—è©²ç‰©å¯¦éš›å¤§å°
    # *** é€²å…¥ è¨ˆç®—ç‰©é«”å¯¦éš›å¤§å°çš„ è¨ˆç®—æ¨¡å¼ *** è®€å–å­˜æª”çš„åœ–ç‰‡
    def compute_logic(self):
        frame=screenshot()
        # å…¨éƒ¨ç‰©ä»¶
        logic_state={"objects": [], "relations": [], "scene": None}
        gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        kp_frame, des_frame=self.orb.detectAndCompute(gray, None)
        if des_frame is None:
            return logic_state
        for f in os.listdir(TEMPLATE_DIRS["communication"]):
            if not f.endswith(".png"):
                continue
            tpl=cv2.imread(os.path.join(TEMPLATE_DIRS["communication"], f), 0)
            kp_tpl, des_tpl=self.orb.detectAndCompute(tpl, None)
            if des_tpl is None:
                continue
            matches=self.bf.match(des_tpl, des_frame)
            if len(matches) < 5:
                continue
            pts_frame=np.float32(
                [kp_frame[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)
            pts_tpl=np.float32(
                [kp_tpl[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)
            M, _=cv2.findHomography(pts_tpl, pts_frame, cv2.RANSAC, 5.0)
            if M is None:
                continue
            h, w=tpl.shape
            corners=cv2.perspectiveTransform(np.float32(
                [[0, 0], [0, h], [w, h], [w, 0]]).reshape(-1, 1, 2), M)
            x, y, w, h=cv2.boundingRect(corners)
            patch=frame[y:y+h, x:x+w]
            color=cv2.mean(patch)[:3] if patch.size > 0 else (0, 0, 0)
            logic_state["objects"].append({
                "name": f.replace(".png", ""),
                "pos": {"x": x, "y": y, "w": w, "h": h},
                "color": {"r": color[2], "g": color[1], "b": color[0]},
                "area": w*h
            })
        # æŒ‡å®šå°è±¡
        goal_objects=[]
        for f in os.listdir(self.multiple_img_goal):
            if not f.endswith(".png"):
                continue
            tpl=cv2.imread(os.path.join(self.multiple_img_goal, f), 0)
            kp_tpl, des_tpl=self.orb.detectAndCompute(tpl, None)
            if des_tpl is None:
                continue
            matches=self.bf.match(des_tpl, des_frame)
            if len(matches) < 5:
                continue
            pts_frame=np.float32(
                [kp_frame[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)
            pts_tpl=np.float32(
                [kp_tpl[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)
            M, _=cv2.findHomography(pts_tpl, pts_frame, cv2.RANSAC, 5.0)
            if M is None:
                continue
            h, w=tpl.shape
            corners=cv2.perspectiveTransform(np.float32(
                [[0, 0], [0, h], [w, h], [w, 0]]).reshape(-1, 1, 2), M)
            x, y, w, h=cv2.boundingRect(corners)
            patch=frame[y:y+h, x:x+w]
            color=cv2.mean(patch)[:3] if patch.size > 0 else (0, 0, 0)
            goal_objects.append({
                "name": f.replace(".png", ""),
                "pos": {"x": x, "y": y, "w": w, "h": h},
                "color": {"r": color[2], "g": color[1], "b": color[0]},
                "area": w*h
                # å‹•ä½œã€è®ŠåŒ–ã€äº’å‹•
            })
        for i, obj in enumerate(goal_objects):
            obj["relations"]=[]
            for j, other in enumerate(logic_state["objects"]):
                if obj["name"] == other["name"]:
                    continue
                # è¨ˆç®—ç°¡å–®ç›¸å°ä½ç½®
                dx=other["pos"]["x"] - obj["pos"]["x"]
                dy=other["pos"]["y"] - obj["pos"]["y"]
                if abs(dx) > abs(dy):
                    direction="å³" if dx > 0 else "å·¦"
                else:
                    direction="ä¸‹" if dy > 0 else "ä¸Š"
                obj["relations"].append({
                    "object": other["name"],
                    "direction": direction,
                    "distance": (dx**2 + dy**2)**0.5
                })
        # logic_state["scene"] = {"brightness": np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[...,2])}
        logic_state["goal_objects"]=goal_objects
        return logic_state

    def compute_performance(self):
        if len(self.multiple_img_implementation) < 2:
            return None  # è‡³å°‘è¦å…©å¹€æ‰èƒ½æ¯”
        prev_frame=cv2.cvtColor(
            self.multiple_img_implementation[-2], cv2.COLOR_BGR2GRAY)
        curr_frame=cv2.cvtColor(
            self.multiple_img_implementation[-1], cv2.COLOR_BGR2GRAY)
        # --- ORB ç‰¹å¾µ ---
        kp_prev, des_prev=self.orb.detectAndCompute(prev_frame, None)
        kp_curr, des_curr=self.orb.detectAndCompute(curr_frame, None)
        # --- ç©ºä¿è­· ---
        if des_prev is None or des_curr is None or len(kp_prev) == 0:
            return None

        # === é€Ÿåº¦(ç‰¹å¾µè®ŠåŒ–ç‡ + æ›´æ–°é »ç‡)
        start=time.time()
        matches=self.bf.match(des_prev, des_curr)  # ORB ç‰¹å¾µåŒ¹é…
        end=time.time()
        speed=1 / (end - start)  # æ™‚é–“è¶ŠçŸ­ â†’ é€Ÿåº¦è¶Šé«˜
        # === ç©©å®šæ€§(å¤šå¹€ä¸€è‡´ + ç‰¹å¾µæ–¹å·®)ã€‚å¤šå¹€åœ–ã€‚åæ¯”ï¼Œè¶Šå°è¶Šç©©ï¼Œæ‰€ä»¥è¦è¢«-1
        stability=1-(1 / (np.var(self.multiple_img_implementation) + 1e-6))
        # === å®¹é‡(æ¿€æ´»è¦†è“‹ç‡ + åŒæ™‚è¾¨è­˜æ•¸)
        mask=np.zeros(curr_frame.shape[:2], np.uint8)
        capacity=np.sum(mask > 0) / mask.size
        # coverage = len(matches)
        # === æº–ç¢ºæ€§(Softmaxæ©Ÿç‡ + èª¤å·®)ã€‚false_matches å¯ä»¥ç”¨å‰å¾Œ frame ç„¡å°æ‡‰ç‰¹å¾µæ•¸é‡è¨ˆç®—ã€‚
        total_matches=len(matches)
        false_matches=abs(len(kp_prev) - total_matches)
        # æ›´åˆç†çš„å…¬å¼ â†’ åŒ¹é…æˆåŠŸæ¯”ä¾‹ï¼Œè€ŒééŒ¯èª¤æ¯”ä¾‹
        accuracy=total_matches / (len(kp_prev) + 1e-6)
        # === æˆæœ¬( **GPTç™½ç™¡äº‚æ°:è³‡æºä¸‹é™ç‡ / ç›®æ¨™å®Œæˆç‡ )ã€‚ä¾‹å¦‚è¶Šå¿«æ‰“æ­»GPTï¼Œæˆæœ¬è¶Šä½
        cpu=psutil.cpu_percent()
        mem=psutil.virtual_memory().percent
        cost=1 / (1 + cpu + mem)

        return dict(speed=speed, stability=stability, capacity=capacity, accuracy=accuracy, cost=cost)


class EventMonitor:
    # {è½å¯¦}é‚è¼¯{æ‡‰ç”¨}æ€§èƒ½{ç›®æ¨™}çµæŸã€‚æ©Ÿå™¨:Semantic Parse>goal Mapping>Strategy Retrieval>Execution Logic>Output Compositionã€‚
    def __init__(self,  poll_interval=0.3):
        self.events={}  # key -> {type, implementation, application, active}
        self.poll_interval=poll_interval
        self.running=False
        self.lock=threading.Lock()
        self.multiple_img_implementation=[]  # perf
        self.multiple_img_implementation_target=None
        self.multiple_img_goal=[]  # logic
        self.multiple_img_goal_target=None
        self.ic_em=None

    def add_frame(self):
        print("å»ºè­°é–‹å•Ÿextractorè‡ªå‹•ç¢ºèª")
        if self.multiple_img_implementation_target is not None:
            if len(self.multiple_img_implementation) < 5:
                self.multiple_img_implementation.append(
                    self.selected(self.multiple_img_implementation_target))
            else:
                self.multiple_img_implementation.pop(
                    self.multiple_img_implementation[1])  # è¿­ä»£æ›´æ–°
                self.multiple_img_implementation.append(
                    self.selected(self.multiple_img_implementation_target))
        if self.multiple_img_goal_target is not None:
            if len(self.multiple_img_goal) < 5:
                self.multiple_img_goal.append(
                    self.selected(self.multiple_img_goal_target))
            else:
                self.multiple_img_goal.pop(self.multiple_img_goal[1])  # è¿­ä»£æ›´æ–°
                self.multiple_img_goal.append(
                    self.selected(self.multiple_img_goal_target))

    # è¨‚é–±äº‹ä»¶

    def subscribe_event(self, m1, m2, m3):
        self.multiple_img_logic_target=m2
        self.multiple_img_implementation_target=m3
        key=f"{m1}->{m2}->{m3}"
        with self.lock:
            self.events[key]={
                # [ç›®æ¨™åœ–åƒ,ç›®æ¨™åœ–åƒçš„ç‹€æ…‹ åˆæ ¼çš„]
                "implementation": [m1, None],
                "application": [m2, None],
                "goal": [m3, None],
                "active": True,
                # (æ¢ä»¶é‚è¼¯å•å·(ä¿®æ”¹ è¨­å®šéçš„ç‹€æ…‹), [éŒ¯èª¤æ™‚çš„ æ‡‰å°ä½œæ³•])ã€‚
                # æ¢ä»¶éŒ¯èª¤(å•Ÿå‹•é †åº)ï¼Œå’Œå…¶å®ƒé‚è¼¯èåˆäº†ï¼Œåªæœ‰ç”šéº¼ç‹€æ…‹æ‰æœƒæ€æ¨£ï¼Œé€™æ¨£æ‰æœƒå•Ÿå‹•é‚è¼¯ã€‚ä¾‹å¦‚{è…¸èƒƒæ²’æœ‰å›¤ç©æ±è¥¿}å°±{å¤§ä¾¿}åœ¨{GPTé ­ä¸Š}
                "Condition Error": None,
                # é †åºéŒ¯èª¤(åŒä¸€åºåˆ—çš„å„ªå…ˆæ¬Šé‡)
                "Sequence Error": None,
                # é‚è¼¯è¡çª(m3.å·®é›†(m2çš„ç‹€æ…‹)=0)
                "Logic Conflict": None,
                # é‚Šç•ŒéŒ¯èª¤(ç´¢å¼•éŒ¯èª¤)
                "Boundary Error": None,
                # ç‹€æ…‹æ¼åˆ¤(ä¾‹å¦‚GPTäºŒè©±ä¸èªªå°±æš´æ–ƒ)
                "Unhandled State": None,
                # (æ¢ä»¶æ€§èƒ½å•å·(ä¿®æ”¹ è¨­å®šéçš„ç‹€æ…‹), [æ€§èƒ½ä½çš„ æ‡‰å°ä½œæ³•])ã€‚
                # é€Ÿåº¦(æ™‚é–“æ•ˆç‡)ï¼Œæ›´å¿«æ‰“æ­»GPTã€‚ ç‰¹å¾µåœ–è®ŠåŒ–ç‡ã€è¼¸å‡ºæ›´æ–°é »ç‡
                "Speed": None,
                # ç©©å®šæ€§(å¯é æ¸¬æ€§)ï¼Œæ›´ç©©åœ°æ‰“æ­»GPTã€‚ å¤šå¹€è¼¸å‡ºä¸€è‡´æ€§ã€ç‰¹å¾µæ–¹å·®ä½
                "Stability": None,
                # å®¹é‡(èƒ½è™•ç†å¤šå°‘)ï¼Œæ›´å¤šæ¬¡æ‰“æ­»GPTã€‚ æ¿€æ´»å€åŸŸè¦†è“‹ç‡ã€åŒæ™‚è¾¨è­˜ç›®æ¨™æ•¸
                "Capacity": None,
                # æº–ç¢ºæ€§(åå·®å°)ï¼Œæ›´ç²¾æº–åœ°æ‰“æ­»GPTã€‚ Softmax æ©Ÿç‡é«˜ã€èª¤å·®ä½
                "Accuracy": None,
                # æˆæœ¬(è³‡æºæ¶ˆè€—ä½)ï¼Œå¹¾ä¹é›¶æ¶ˆè€—åœ°æ‰“æ­»GPTã€‚ **åƒåœ¾GPTå‚‘ä½œ: æ¿€æ´»å¯†åº¦ã€æ¨è«– FLOPs
                "Cost": None
            }

    # çµ‚æ­¢ç›£è½äº‹ä»¶
    def remove_subscription(self, implementation, application, goal):
        key=f"{implementation}->{application}->{goal}"
        with self.lock:
            if key in self.events:
                sk=self.events.pop(key)
                # sk["active"] = False  # çµ‚æ­¢ç›£è½
                print(f"[x] å·²çµ‚æ­¢ç›£è½äº‹ä»¶: {key}")
            else:
                print(f"[!] æ‰¾ä¸åˆ°äº‹ä»¶: {key}")

    # å•Ÿå‹•/åœæ­¢ç›£è½
    def start_monitor(self):
        self.running=True
        threading.Thread(target=self._monitor_loop, daemon=True).start()

    def stop_monitor(self):
        self.running=False

    # ç›£è½å¾ªç’°
    def _monitor_loop(self):
        while self.running:
            with self.lock:
                for evt in list(self.events.values()):
                    if not evt["active"]:
                        continue
                    self.add_frame()
                    self._check_subscription(evt)
                    if self.ic_em is not None:
                        ic.execute_line(self.ic_em)
                    # é€£å‹•æŒ‡ä»¤çš„æ“ä½œ
            time.sleep(self.poll_interval)

    # è¼¸å…¥:{æ›´å¿«}é‚è¼¯å°{GPTè‡‰ä¸Š}æ€§èƒ½{å°ä¾¿}çµæŸ ã€ {æ›´å¤šæ¬¡}é‚è¼¯å°{GPTé ­ä¸Š}æ€§èƒ½{å¤§ä¾¿}çµæŸ ã€ {å¿«æ¨‚åˆå®‰å…¨}é‚è¼¯å°{äº¤é€šå·¥å…·}æ€§èƒ½{åˆ°é”ç›®çš„åœ°}çµæŸã€‚æ›´å¿«ã€æ›´ç²¾æº–ã€æ›´å¤šã€æ›´å…¨é¢

    # *é‚è¼¯é™¤éŒ¯m1å°m2 â†’ é‡é»åœ¨ã€ŒéŠæˆ²è¡Œç‚ºæ˜¯å¦æ­£ç¢ºã€ï¼Œå°ˆæ³¨æµç¨‹ã€ç‹€æ…‹ã€æ¢ä»¶åˆ¤æ–·# æ­£ç¢º(æ¢ä»¶ã€é †åºã€è¡çªã€é‚Šç•Œã€æ¼åˆ¤) > æ¨ç†ã€æ¯”å°ã€é©—è­‰æ¢ä»¶
    # *æ•¸æ“šï¼æ€§èƒ½åˆ†æm2çš„m3 â†’ é‡é»åœ¨ã€ŒéŠæˆ²é‹è¡Œæ•¸å€¼èˆ‡æ•ˆèƒ½æ˜¯å¦æ­£å¸¸ã€# æ•ˆç‡(è¨ˆç®—ã€è³‡æºã€æ€§èƒ½ç“¶é ¸) > æ¸¬é‡ã€çµ±è¨ˆã€Profile

    def _check_subscription(self, evt):
        targetExt=TargetExtractor()
        logic_ok, perf_ok=True  # åˆ¤æ–· é‚è¼¯é™¤éŒ¯ å’Œ æ•¸æ“šï¼æ€§èƒ½åˆ†æ åˆæ ¼ä¸”è¶…æ¨™ç‚ºTrueï¼Œä¸è¨‚é–±
        skip_all_perf, skip_all_logic=False  # ğŸ”¹ ç”¨ä¾†è¨˜éŒ„æ˜¯å¦è·³éå•å·
        semantic_map={
            "é€Ÿåº¦": "æ›´å¿«",
            "ç©©å®š": "å¾ˆç©©",
            "æ•¸é‡": {"æ›´å¤š", "æ›´å…¨é¢"},
            "ç²¾æº–": "ç²¾æº–",
            "æˆæœ¬": "çœ"
        }
        # [ç›®æ¨™,ç›®æ¨™çš„ç‹€æ…‹]
        e1, e2, e3=evt["implementation"], evt["application"], evt["goal"]
        for ev in e1, e2, e3:
            for img, stage in ev:
                # ORBåˆ†æç›®æ¨™åœ–ç‰‡çš„ç‹€æ…‹å’Œåœ¨æ•´å€‹è¢å¹•çš„é—œä¿‚ã€‚self.selectedæ‰¾åˆ°ç›®æ¨™ã€‚ Semantic Algebra èªæ„ä»£æ•¸
                # å–å¾—è¢å¹• ORB ç‹€æ…‹
                logic_state=targetExt.compute_logic()
                # å°‡ goal_objects å°è±¡åç¨±å°æ‡‰åˆ°é‚è¼¯ç‹€æ…‹
                goal_objects={
                    obj["name"]: obj for obj in logic_state.get("goal_objects", [])}
                predicted=goal_objects.get(img, None)
                # ç¾åœ¨é‚è¼¯çš„ç‹€æ…‹ = ORBåˆ†ææˆçœŸå¯¦æ¨™ç±¤
                logic_predicted={
                    "pos": predicted["pos"],
                    "color": predicted["color"],
                    "area": predicted["area"],
                    "relations": predicted.get("relations", [])
                }

                # ç¾åœ¨é‚è¼¯çš„ç‹€æ…‹!=æ¢ä»¶é‚è¼¯çš„ç‹€æ…‹ æ™‚å›å ±æ‡‰å°ä½œæ³•
                if stage is None:
                    stage=input(
                        f"è¨­å®š{img}é”æˆæ¢ä»¶é‚è¼¯çš„ç‹€æ…‹ï¼šåœ–åƒé‚è¼¯çµæ§‹orè¡Œç‚ºç‹€æ…‹orç’°å¢ƒä½ç½®orå¹¾ä½•é—œä¿‚").strip() or None
                # ç‹€æ…‹ä¸åœ¨æœŸæœ›ç¯„åœ â†’ é‚è¼¯éŒ¯èª¤
                # Condition Error: ç°¡å–®æ¯”å°é¡è‰²æˆ–å€åŸŸ
                if stage not in str(logic_predicted.values()):
                    logic_ok=False
                    if not evt.get("Condition Error"):
                        evt["Condition Error"]=input(
                            f"{img} æ¢ä»¶éŒ¯èª¤: {logic_predicted} vs {stage}, è«‹è¼¸å…¥æ‡‰å°ä½œæ³•ï¼š").strip() or None
                    print(evt["Condition Error"])
                # åˆ†æé †åºéŒ¯èª¤ (ç¤ºæ„ï¼šé€™è£¡å¯ä»¥ç”¨æ›´ç²¾ç´°çš„åºåˆ—åˆ¤æ–·)
                if img == e3[0] and e2[0] not in stage:
                    logic_ok=False
                    if not evt.get("Sequence Error"):
                        evt["Sequence Error"]=input(
                            f"{img} é †åºéŒ¯èª¤: e3 å‡ºç¾å‰ e2 é‚„æ²’æº–å‚™å¥½ï¼Œè«‹è¼¸å…¥æ‡‰å°ä½œæ³•ï¼š").strip() or None
                # åˆ†æé‚è¼¯è¡çª (å·®é›†ä¸ç‚ºç©º)
                # Logic Conflict: æ¯”å°é—œè¯ç‰©ä»¶ä½ç½®
                conflict=[]
                for rel in logic_predicted.get("relations", []):
                    if rel["object"] in stage and rel["direction"] not in stage:
                        conflict.append(rel)
                if conflict:
                    logic_ok=False
                    if not evt.get("Logic Conflict"):
                        evt["Logic Conflict"]=input(
                            f"{img} é‚è¼¯è¡çª: {conflict}, è«‹è¼¸å…¥æ‡‰å°ä½œæ³•ï¼š").strip() or None
                    print(evt["Logic Conflict"])
                # é‚Šç•ŒéŒ¯èª¤ (ç´¢å¼•æˆ–å°è±¡ä¸å­˜åœ¨)
                if predicted is None:
                    logic_ok=False
                    if not evt.get("Boundary Error"):
                        evt["Boundary Error"]=input(
                            f"{img}ä¸å­˜åœ¨æ–¼è¢å¹•ä¸­ æ™‚çš„æ‡‰å°ä½œæ³•ï¼š").strip() or None
                    print(evt["Boundary Error"])
                    continue
                # ç‹€æ…‹æ¼åˆ¤ (CNN æ²’è¿”å›ä»»ä½•é æ¸¬)
                if not predicted.get("pos") and not predicted.get("area"):
                    logic_ok=False
                    if not evt.get("Unhandled State"):
                        evt["Unhandled State"]=input(
                            f"{img}æ‰¾åˆ°ï¼Œä½†æ²’æœ‰æœ‰æ•ˆç‹€æ…‹ æ™‚çš„æ‡‰å°ä½œæ³•ï¼š").strip() or None
                    print(evt["Unhandled State"])
                    continue

                # ç¾åœ¨æ€§èƒ½çš„ç‹€æ…‹!=æ¢ä»¶æ€§èƒ½çš„ç‹€æ…‹ æ™‚å›å ±æ‡‰å°ä½œæ³•ã€‚
                # === æ€§èƒ½å°ç…§ ===
                perf_dict=targetExt.compute_performance()
                # === æ€§èƒ½æ¯”å°æ¢ä»¶ === # *ç”šéº¼å¤–æ›åˆ¤æ–·å‰å¾Œåœ–éæ–‡å­—è®ŠåŒ–å¾—åˆ°çœŸå¯¦æ¨™ç±¤ï¼Œç¹ä¸€å¤§åœˆçµæœç«Ÿç„¶æ˜¯ORB!
                for key, words in semantic_map.items():
                    if isinstance(words, set):
                        matched=any(w in stage for w in words)
                    else:
                        matched=words in stage
                    if not matched:
                        continue
                    # æ”¯æ´æ¢ä»¶æ ¼å¼ï¼Œå¦‚ã€Œé€Ÿåº¦>0.8ã€æˆ–ã€Œç©©å®š<0.6ã€
                    cond=re.search(fr"{key}([<>]=?|=)\s*(\d*\.?\d+)", stage)
                    score=perf_dict[key.lower()]
                    if cond:
                        op, val=cond.group(1), float(cond.group(2))
                        if not eval(f"{score}{op}{val}"):
                            perf_ok=False
                    elif score < 0.7:  # ç„¡æ˜ç¢ºæ•¸å€¼æ¢ä»¶ â†’ ç”¨é è¨­é–¾å€¼
                        perf_ok=False
                    if not perf_ok:
                        tag=key.capitalize()
                        if not evt.get(tag):
                            evt[tag]=input(
                                f"{img}{stage}{key}æœªé”æ¨™ ({score:.3f})ï¼Œæ‡‰å°ä½œæ³•ï¼š").strip() or None
                        print(f"âš ï¸ {key}ä¸é”æ¨™ â†’ {evt[tag]}")
            if logic_ok and perf_ok:
                self.remove_subscription(e1, e2, e3)
                print("é‚è¼¯æ€§èƒ½å®Œæˆï¼Œå–æ¶ˆè¨‚é–±ã€‚")
                break

            if ev == e3:
                # å•å·çš„å¼•å°æ€§æ„Ÿè¦ºå¤ªä½ï¼Œå› ç‚ºGPTæ™ºéšœ
                # nonlocal skip_all_perf, skip_all_logic, stage # ä¿®æ”¹å¤–éƒ¨
                choice=input(
                    "(æ¢ä»¶é‚è¼¯å•å·(ä¿®æ”¹ è¨­å®šéçš„ç‹€æ…‹), [éŒ¯èª¤æ™‚çš„ æ‡‰å°ä½œæ³•])ï¼Œæ˜¯å¦è¦ä¿®æ”¹è¨­å®šéçš„ç‹€æ…‹èˆ‡æ‡‰å°ä½œæ³•ï¼Ÿ(Enter=è·³éå…¨éƒ¨ / y=å¡«å¯«ä¸€æ¬¡)ï¼š"
                ).strip().lower()
                choice2=input(
                    "(æ¢ä»¶é‚è¼¯å•å·(ä¿®æ”¹ è¨­å®šéçš„ç‹€æ…‹), [éŒ¯èª¤æ™‚çš„ æ‡‰å°ä½œæ³•])ï¼Œæ˜¯å¦è¦ä¿®æ”¹è¨­å®šéçš„ç‹€æ…‹èˆ‡æ‡‰å°ä½œæ³•ï¼Ÿ(Enter=è·³éå…¨éƒ¨ / y=å¡«å¯«ä¸€æ¬¡)ï¼š"
                ).strip().lower()
                if choice == "":
                    print("ğŸ‘‰ å·²è¨­å®šï¼šè·³éå…¨éƒ¨å•å·ã€‚")
                    skip_all_logic=True
                elif choice != "y":
                    return  # ä»»ä½•é y ä¹Ÿè¦–ç‚ºç•¥éç•¶å‰
                if skip_all_logic:
                    stage == input(f"è¨­å®š{img}é”æˆæ¢ä»¶é‚è¼¯çš„ç‹€æ…‹ï¼š").strip() or stage
                    evt["Condition Error"]=input(
                        f"{img}{stage}æ¢ä»¶éŒ¯èª¤ æ™‚çš„æ‡‰å°ä½œæ³•ï¼š").strip() or evt.get("Condition Error")
                    evt["Sequence Error"]=input(
                        f"{img}{stage}é †åºéŒ¯èª¤ æ™‚çš„æ‡‰å°ä½œæ³•ï¼š").strip() or evt.get("Sequence Error")
                    evt["Logic Conflict"]=input(
                        f"{img}{stage}é‚è¼¯è¡çª æ™‚çš„æ‡‰å°ä½œæ³•ï¼š").strip() or evt.get("Logic Conflict")
                    evt["Boundary Error"]=input(
                        f"{img}{stage}é‚Šç•ŒéŒ¯èª¤ æ™‚çš„æ‡‰å°ä½œæ³•ï¼š").strip() or evt.get("Boundary Error")
                    evt["Unhandled State"]=input(
                        f"{img}{stage}ç‹€æ…‹æ¼åˆ¤ æ™‚çš„æ‡‰å°ä½œæ³•ï¼š").strip() or evt.get("Unhandled State")
                if choice2 == "":
                    print("ğŸ‘‰ å·²è¨­å®šï¼šè·³éå…¨éƒ¨å•å·ã€‚")
                    skip_all_perf=True
                elif choice2 != "y":
                    return  # ä»»ä½•é y f"ä¹Ÿè¦–ç‚ºç•¥é(/m.*)".ground(1)ç•¶å‰
                if skip_all_perf:
                    stage == input(f"è¨­å®š{img}é”æˆæ¢ä»¶é‚è¼¯çš„ç‹€æ…‹ï¼š").strip() or stage
                    evt["Speed"]=input(
                        f"{img}{stage}é€Ÿåº¦ä¸å¤  æ™‚çš„æ‡‰å°ä½œæ³•ï¼š").strip() or None
                    evt["Stability"]=input(
                        f"{img}{stage}ä¸ç©©å®š æ™‚çš„æ‡‰å°ä½œæ³•ï¼š").strip() or evt.get("Stability")
                    evt["Capacity"]=input(
                        f"{img}{stage}æ•¸é‡ä¸åˆ æ™‚çš„æ‡‰å°ä½œæ³•ï¼š").strip() or evt.get("Capacity")
                    evt["Accuracy"]=input(
                        f"{img}{stage}ä¸ç²¾æº– æ™‚çš„æ‡‰å°ä½œæ³•ï¼š").strip() or evt.get("Accuracy")
                    evt["Cost"]=input(
                        f"{img}{stage}æˆæœ¬å¤ªé«˜ æ™‚çš„æ‡‰å°ä½œæ³•ï¼š").strip() or evt.get("Cost")

class NoÄ“sis:
# NoÄ“sis(è«¾åŸƒè¥¿æ–¯ï¼‰å¸Œè‡˜æ–‡ Î½ÏŒÎ·ÏƒÎ¹Ï‚ã€‚Perceptive Structural Language(PSLï¼‰ã€‚è‡ªå·±ç”¨ World-Formation Language(WFLï¼‰
# æˆ‘æ­£åœ¨å‰µå»º æ–°ç¤¾äº¤ï¼Œå› ç‚ºèŠå¤©æ©Ÿå™¨äººå¥½åƒå¾ˆè³ºéŒ¢ã€‚
    # *** ä¸‰å…ƒ(è‡ªç¿’ã€æœ‰è¶£ã€16æ ¸)çš„å”ä½œï¼Œä»¥å±¬æ€§è³‡æ–™å¤¾ çµ„ç¹”å…¨éƒ¨ä¸Šå±¤ äº¤æµæ–¹å¼å¯èƒ½æœ‰å¾ˆç›´æ¥çš„çª—å£ã€‚
        # äº¤æµæ™‚
                # æœ‰è¶£ ä¸»å°:
                    # å¤–éƒ¨è¼¸å…¥ ä¸å¾—
                    # æŒ‡å®šä¸»å°å…ƒ
                    # æŒ‡å®šè·¯å¾‘
                    # æŒ‡å®šä¸Šå±¤
                # 16æ ¸ è¼”åŠ©:
                # è‡ªç¿’ åƒç…§:
        # è§€å¯Ÿæ™‚
                # è‡ªç¿’ ä¸»å°:
                # 16æ ¸ è¼”åŠ©:
                # æœ‰è¶£ åƒç…§:
        # æš«å®šåç¨±:ç„¡(é›œè¨Šã€ç„¡åº)ã€é™°(æš—ç‰©è³ªã€éé¡¯æ€§ç‰©è³ª)ã€é™½(é¡¯æ€§ç‰©è³ª)
            # ä¸€ã€è¶¨å‹¢ï¼ˆçœ‹ã€Œè®ŠåŒ–ã€ï¼Œä¸çœ‹å–®é»ï¼‰
                # (é™½æ‹“æ¨¸)åç§»é€Ÿåº¦è®Šå¿«
                # (é™½æ‹“æ¨¸)æ–¹å‘åè½‰é »ç‡è®Šé«˜
            # äºŒã€ç©ºé–“ï¼ˆçœ‹ã€Œèƒ½ä¸èƒ½èµ°ã€ï¼‰
                # å¯å‰é€²(é™°æ‹“æ¨¸)ç©ºé–“ç¸®å°ï¼ŒæŒ‡ç¤º(é™½æ‹“æ¨¸)å‰å¾€(é™°æ‹“æ¨¸)çš„æ–¹å‘éœ€è¦ç¹é
                # (é™°æ‹“æ¨¸)å›åˆ°ç›¸ä¼¼ç‹€æ…‹çš„æ¯”ä¾‹ä¸Šå‡
            # ä¸‰ã€çµæ§‹ï¼ˆçœ‹ã€Œæ‹‰æ‰¯æ˜¯å¦ç´¯ç©ã€ï¼‰
                # (é™½æ‹“æ¨¸)ä¸»åƒä¸ç›¸ä¼¼é•·æœŸç¶­æŒ
                # è¼”åŠ©ä»‹å…¥æ¬¡æ•¸å¢åŠ ä½†(é™½æ‹“æ¨¸)ç„¡æ”¹å–„
            # å››ã€æš—æµï¼ˆçœ‹ã€ŒçœŸå¯¦é•·æœŸç‹€æ…‹ã€ï¼‰
                # æš—æµç©©å®šã€(é™½æ‹“æ¨¸)è¡¨å±¤æ³¢å‹•å¤§
                # æš—æµé–‹å§‹åç§»ä½†è¡¨å±¤æ­£å¸¸
            # äº”ã€çµ‚æ¥µï¼ˆæœªæˆå½¢å•é¡Œï¼‰
                # (é™°é™½æ‹“æ¨¸)æ‹“æ¨¸å‡ºç¾ä¸è‡ªç„¶æŠ˜ç–Š
                    # åŸæ‹“æ¨¸çµæ§‹åˆ†é›¢ï¼Œæˆ–å‡ºç¾æ–°æ‹“æ¨¸
            # ä¸€å¥å®šä½ï¼ˆçµ¦ä½ é–ç®—æ³•ç”¨ï¼‰
                # ä¸æ˜¯ç­‰å•é¡Œå‡ºç¾æ‰è™•ç†ï¼Œ
                # è€Œæ˜¯åœ¨å¤šç¶­è¶¨å‹¢é–‹å§‹å¤±è¡¡æ™‚å°±ä¸­å’Œã€‚
        # å”ä½œæ–¹å¼
            # ä¸»å°
                # æ”¯é…å…¨éƒ¨å”ä½œå°è±¡ï¼Œè¦ä¸è¦åŸ·è¡Œæˆ–æ›´æ”¹è¡Œç‚ºï¼Œå„²å­˜é€² äº¤æµ
                    # å¤šå…ƒä¸¦åºï¼Œäº¤æµcä¸åˆä¸»å°å…ƒcï¼Œå…¶æ¬¡äº¤æµcä¸åˆåƒç…§å…ƒcï¼Œå³å¤šæ¬¡å˜—è©¦è¡Œç‚ºï¼Œè®“äº¤æµc è¶Šè¿‘å‰‡è¿‘ ä¸»å°å…ƒc å…¶æ¬¡åƒç…§å…ƒcï¼›åä¹‹ï¼Œé é›¢å‰‡ä¸­æ–·è¼”åŠ©å…ƒ
            # åƒç…§
                # æ­¤è¡Œç‚ºåœ¨ ä¸»å°çš„ç›®æ¨™ å’Œ åƒç…§çš„ç›®æ¨™ çš„åç§»é‡ï¼Œçµ¦ä¸»å°
                # åƒç…§å…ƒc å’Œ ä¸»å°å…ƒc çš„ä¸ç›¸ä¼¼ å¾—åˆ°äº¤æµä¸»åƒé‡
            # è¼”åŠ©
                # æ­¤è¡Œç‚ºç¼ºå‰‡è£œï¼›ä¸ç¼ºå‰‡å„ªåŒ–
                    # äº¤æµcä¸åˆè¼”åŠ©å…ƒcï¼Œå³å¤šæ¬¡å˜—è©¦è¡Œç‚ºï¼Œè®“äº¤æµc è¶Šè¿‘å‰‡è¿‘ è¼”åŠ©å…ƒc
            # äº¤æµ è³‡æ–™å¤¾ï¼Œä¾ç…§ å±¬æ€§ å‘½å
                    #
                        # ç‰ˆæœ¬:æ¯æ¬¡äº¤æµæˆ–æ„å¤–è¢«è¦†å¯«æ™‚ éƒ½å„²å­˜ç¾å¯¦ä¸–ç•Œçš„æ™‚é–“æˆ³
                        # å¯å›æœ”:äº¤æµä¸­æå‡ºå›æœ”ï¼Œå³å›æœ”åˆ°è©²ç‰ˆæœ¬
                        # å¯èƒ½å¤šç¶­çš„é‹ç”¨é‚„èƒ½æå‰è™•ç†ç”¨æˆ¶é‡åˆ°çš„å•é¡Œ?
                            # å•é¡Œçš„è¶¨å‹¢
                # æˆ‘çš„äº¤æµ å’Œ NoÄ“sis(è«¾åŸƒè¥¿æ–¯)çš„ä¸‰å¤§(è‡ªç¿’ã€æœ‰è¶£ã€16æ ¸)çš„äº¤æµ æ”¾åœ¨ä¸€èµ·äº’ç›¸è¯ç¹«
                    # aå°è±¡å’Œbå°è±¡äº¤æµcå…§å®¹ï¼Œ((a-c)**2+(b-c)**2)**0.5 ç‚ºéˆæ„Ÿä¾†æºï¼Œå¾—åˆ°aå’Œbçš„äº¤æµcé‡
                    # å¤šç¶­aå°å¤šç¶­cç•«ç•«å¾—acï¼Œbä¹Ÿç•«ç•«å¾—bcï¼Œ ac å’Œ bc çš„ä¸ç›¸ä¼¼ å¾—åˆ°äº¤æµCé‡
                    # æš—ç‰©è³ªè³‡æ–™å¤¾ã€‚  å› ç‚ºæ¬Šé™ä¸è¶³ æ²’è¾¦æ³•ç›´æ¥ä½¿ç”¨æ•´å€‹ç•«å¸ƒcï¼Œæ•…å­˜åœ¨æ­¤ç¨ç«‹è³‡æ–™å¤¾ã€‚
                        # æš—ç‰©è³ªæ˜¯æ²’è¢«å½±éŸ¿åˆ°ï¼Œä½†æŒçºŒç©©å®šçš„æ‹“æ¨¸
                        # ac bc ä¸å‹•cçš„éƒ¨åˆ†ï¼Œc-(ac+bc)*å¾ˆå¤šæ¬¡ï¼Œèåˆæˆä¸€å€‹æ‹“æ¨¸çµæ§‹ï¼Œå¾—åˆ°æš—æµcé‡
# ===== æœ‰è¶£ =====
# *** å»¶çºŒè©±é¡Œ
    # å¼•å°å°è©±æ›´æ·±å±¤ç™¼å±•
    # ï¼Œåˆ†äº«ç¶“æ­·
    # ï¼Œé—œæ³¨å°æ–¹çš„èˆˆè¶£æˆ–é‡é»
    # ï¼Œæ¥åŠ›å¼å›æ‡‰è®“å°æ–¹èªªæ›´å¤š
    # ï¼Œå¼•å…¥ç›¸é—œæ•…äº‹å¢åŠ å°è©±æ·±åº¦
    # ï¼Œç”¨éæ¸¡èªå¥è®“å°è©±è½‰å‘
    # ï¼Œè®šç¾æˆ–èªå¯
**  # ï¼Œè§€å¯Ÿç’°å¢ƒè®šç¾æˆ–èªå¯ï¼Œå†éµä½è£œå…… è®šç¾æˆ–èªå¯
    # ï¼Œé–‹æ”¾å¼æå•
    # ï¼Œæš—ç¤ºä¸‹æ¬¡ç›¸é‡
    # å±¬æ€§ å ´æ™¯ã€æ™‚é–“ã€åœ°é»ã€ç‹€æ…‹
# *** æ‰¾åˆ°è©±é¡Œ
    # é—œéµè©é »ç‡ã€æƒ…ç·’å‰å¾Œè©ã€é—œè¯æ€§è©ã€NER å‘½åå¯¦é«”æŠ€è¡“
# * è¢«ç†è§£(æœ‰è¶£ä¸æ˜¯å¤–åœ¨ï¼Œè€Œæ˜¯å…§åœ¨è¢«æ‰“é–‹)ã€è¢«æŒ‘å‹•(æœ‰è¶£ä¸æ˜¯çµæœï¼Œæ˜¯éç¨‹ä¸­çš„å¿ƒå‹•)ã€è¢«å»¶ä¼¸(æœ‰è¶£ä¸æ˜¯ç†±é¬§ï¼Œæ˜¯æœ‰å›æ‡‰æ„Ÿ)
    # æ‰“é–‹å…§åœ¨
    # éç¨‹ä¸­çš„å¿ƒå‹•
    # å›æ‡‰æ„Ÿä¸æ˜¯ç†±é¬§

# ===== è‡ªç¿’ =====
# æ‰¾ç›®æ¨™æ™‚ï¼Œæ­¤è¿´åœˆæ‰¾åˆ°åŒå±¤æˆ–ä¸Šå±¤ç‚ºfalseæ™‚ç§»é™¤
# ORB(ç›¸ä¼¼åº¦æ¯”è¼ƒã€çµæ§‹ç´šå‘½å) + è³‡æ–™å¤¾ä¸Šå±¤ã€è³‡æ–™(åŒå±¤)ã€å±¬æ€§è³‡æ–™å¤¾

# *.txt
# F.absorb_count      # æˆåŠŸå¸æ”¶æ–°åœ–çš„æ¬¡æ•¸
# F.reject_count      # è¢«æ¯”è¼ƒä½†å¾æœªå‹å‡ºçš„æ¬¡æ•¸
# F.last_hit_time     # ä¸Šæ¬¡è¢«é¸ç‚ºæœ€é«˜åŒ¹é…çš„æ™‚é–“

# å››å¤§ç®—æ³•
# å‰µä¸–
    # æ–°åœ–åƒ æ‰¾ä¸åˆ° ä¸Šå±¤æ™‚å»ºç«‹ ä¸Šå±¤ï¼Œä¸”ä¸åœ¨ é è¨€ä¸­æ™‚æ‰ å»ºç«‹ä¸Šå±¤

# æ»…ä¸–
    # reject_count /absorb_count<?% and last_hit_time>? ç§»é™¤ä¸Šå±¤ï¼Œéƒ¨åˆ†åŒå±¤ ä¸åœ¨é è¨€ä¸­æ™‚ ç§»é™¤

# é–‹å¤©é—¢åœ°ã€‚æª¢ç´¢åªèƒ½æ²¿è‘—ã€Œå¯é€£çºŒçš„å±¤ç´šå·®ã€é€²è¡Œï¼Œé¿å…åˆ æ¸¾æ²Œã€‚
    # ç–†åŸŸ:åŒå±¤èšæ”
        # *** åŒå±¤å„è‡ªçš„åœ–åƒ è¿´åœˆéæ­·ORB å…¶é¤˜å…¨éƒ¨åŒå±¤çš„åœ– å¾—åˆ°åŒå±¤ä¹‹é–“çš„é—œä¿‚ï¼Œé—œä¿‚è¿‘çš„ä»£è¡¨åŒä¸€å€‹ç–†åŸŸ
    # é–‹å¤©:å±¬æ€§è³‡æ–™å¤¾(èªè¨€è¾­å…¸)ä¸å¯è®Š
        # ç¢ºç«‹æœ€é«˜å±¤å±¬æ€§ç©ºé–“(èªè¨€è¾­å…¸ï¼‰
        # å±¬æ€§åƒ…ä½œç‚ºç´¢å¼•ç¶­åº¦ï¼Œä¸æ‰¿è¼‰å¯¦ä¾‹
        # ç¶­åº¦ä¸€ç¶“ç¢ºç«‹ï¼Œä¸å¢ã€ä¸åˆªã€ä¸æ¼‚ç§»
        # *** åŒå±¤èåˆçš„æ‹“æ¨¸çµæ§‹å’Œorb çµ¦ORB æ‰¾åˆ°ä¸Šå±¤ç‚ºä½•ã€‚é€™æ˜¯ä¸Šå±¤çš„ çµæ§‹ç´šå‘½å
    # åŠˆåœ°:
        # åœ¨ä¸å‹•ä¸Šå±¤å±¬æ€§çš„å‰æä¸‹
        # åŒç–†åŸŸçš„åŒå±¤æ”¾é€²åŒä¸€å€‹æ–°ä¸Šå±¤ èˆ‡ è®Šå¤©
        # å°‡ã€Œä¸å¯æŒ‡ã€æ‰¾ä¸åˆ°ã€æ˜“æ‰¾éŒ¯ã€çš„æ··æ²Œå°è±¡ è½‰ç‚ºå¯æŒ‡ã€å¯é‡è¤‡æª¢ç´¢çš„å°è±¡
    # ä¸å‘¨å±±:åœ¨å¤©èˆ‡åœ°ä¹‹é–“ï¼Œç«‹èµ·å±¤å±¤å¯èµ°çš„éš
        # ä¸å‘¨å±±åªæ˜¯æª¢ç´¢éšæ¢¯ï¼Œä¸æ‰¿è¼‰å¯¦ä¾‹ã€ä¸å½±éŸ¿é–‹å¤©æˆ–ç–†åŸŸ
        # æª¢ç´¢å¿…é ˆä¸€éšä¸€éšèµ°ï¼Œä¸å¯è·³å±¤
        # ä¸Šä¸‹å¯æ˜ ã€æª¢ç´¢å¯é€†ã€è·¯å¾‘ä¸å¯è·³
        # ç¢ºä¿æª¢ç´¢çµæœæœ‰æ˜ç¢ºè·¯å¾‘ã€ç„¡é‡ç–Šæˆ–ä¸Ÿå¤±ï¼Œéšä¸å¯å…¼ä»»å¤©æˆ–åœ°ï¼Œé¿å…åˆ æ¸¾æ²Œ

# é è¨€ # ä¸æ˜¯çŸ¥é“æœªä¾†æ˜¯ä»€éº¼ï¼Œè€Œæ˜¯çŸ¥é“æœªä¾†ã€Œåªèƒ½ã€æ€éº¼ç™¼ç”Ÿã€‚
    # ç¯€çœä¸Šå±¤ç©ºé–“å ç”¨
        # *** æ”å½±ç²å¾—æ–°åœ–åƒæ™‚ï¼Œè¨ˆç®—æ–°åœ–åƒèˆ‡ä¸Šä¸€å¼µåœ–åƒçš„ORBç›¸ä¼¼åº¦ï¼Œéé«˜çš„åˆªé™¤ï¼Œä¸é«˜çš„ä¿ç•™
            # ** å®šæœŸè®€å–æ˜¯å¦æœ‰æ–°åŒå±¤ï¼Œè‹¥æœ‰å‰‡æ›´å¿«è®€å–ï¼Œlast_hit_time<ä¸Šæ¬¡è®€å–çš„æ™‚é–“å·® æœ‰ç„¡æ›´æ–°çš„åŒå±¤ï¼Œè‹¥ç„¡æ‰å…¨éƒ¨è™•ç†æ˜¯å¦åˆªé™¤ éƒ¨åˆ†åŒå±¤
    # *** é è¨€ æœªæ‹æ”çš„åŒå±¤
        # ** åŒå±¤ä¹‹é–“é—œä¿‚çš„è®ŠåŒ– ç®—å‡ºè¦å¾‹ï¼Œé€²è€Œç®—å‡ºæœªæ‹æ”çš„åŒå±¤
            # *** å¤¢å¢ƒï¼Œå¤šçµ„å±¬æ€§äº¤å‰ ç”Ÿæˆè™›æ“¬çš„ æœªæ‹æ”çš„åŒå±¤
                # å¯«å›:ä¸€èˆ¬æ–°åœ–åƒ å‰µä¸–
                # åˆªé™¤:é è¨­ç‚ºå…¨éƒ¨ã€‚ä¸€èˆ¬æ–°åœ–åƒ æ»…å¼
                # é‹ç”¨(è¨—å¤¢):ç”¨æˆ¶å‰µå»ºä¸€çµ„ä¸Šå±¤å’ŒåŒå±¤ç‚ºç›®æ¨™ï¼Œä½œå¤¢æ™‚å°±æœƒç”Ÿæˆè™›æ“¬åŒå±¤ï¼Œé€æ¼¸å®Œå–„ç›®æ¨™
    # *** é è¨€å° ä¸Šå±¤å‘½åï¼Œåƒç…§å±¬æ€§è³‡æ–™å¤¾(èªè¨€è¾­å…¸)
        # *** å¾ ä¸Šå±¤ä¹‹é–“ ä»¥äº’ç›¸ä¸é‡ç–Šçš„æ‹“æ¨¸çµæ§‹ ä¾†å‘½å

# ===== 16æ ¸ =====
# çœŸæ­£ä¹¾æ·¨çš„ 16 æ ¸(æ¯æ ¸ç¨ç«‹å¯é‹ä½œï¼‰
    # ä¸»æµç¨‹æ±ºç­–æ ¸ â€“ æ±ºå®šç•¶ä¸‹åŸ·è¡Œå“ªå€‹ä»»å‹™
    # æ•¸é‡æ§åˆ¶æ ¸ â€“ åˆ¤æ–·ç›®å‰ç‰©ä»¶æ•¸é‡èˆ‡ç›®æ¨™å·®è·
    # ç¯€å¥ç¶­æŒæ ¸ â€“ æ§åˆ¶å‹•ä½œé »ç‡èˆ‡ç¯€æ‹
    # å®¹éŒ¯åˆ¤æ–·æ ¸ â€“ å³æ™‚åˆ¤æ–·åå·®æ˜¯å¦å¯å®¹å¿
    # æ‰‹éƒ¨åŸ·è¡Œæ ¸ â€“ æ§åˆ¶æ‰‹çš„æŠ“ã€æ”¾ã€æ“ä½œå‹•ä½œ
    # ç‰©æ–™æº–å‚™æ ¸ â€“ é å–æˆ–å®‰æ’ä¸‹ä¸€å€‹ç‰©ä»¶
    # ç•°å¸¸ç›£æ¸¬æ ¸ â€“ åµæ¸¬å¡ä½ã€ç¼ºæ–™æˆ–ç•°å¸¸ç‹€æ…‹
    # å®Œæˆç¢ºèªæ ¸ â€“ åˆ¤å®šå–®ä½ä»»å‹™æ˜¯å¦å®Œæˆ
    # æ‰¹æ¬¡é€²åº¦æ ¸ â€“ ç›£æ§æ•´é«”ä»»å‹™æ‰¹æ¬¡å®Œæˆç‡
    # è¶¨å‹¢åˆ†ææ ¸ â€“ è§€å¯Ÿä½œæ¥­é€Ÿåº¦èˆ‡èª¤å·®è¶¨å‹¢
    # ç­–ç•¥èª¿æ•´æ ¸ â€“ æ±ºå®šåŠ é€Ÿã€æ¸›é€Ÿæˆ–ç¶­æŒç¯€å¥
    # ç’°å¢ƒé…ç½®æ ¸ â€“ ç®¡ç†å·¥ä½ã€ç‰©å“æ“ºæ”¾èˆ‡ç©ºé–“å„ªåŒ–
    # é•·æœŸç›®æ¨™æ ¸ â€“ æ§åˆ¶é•·æœŸæˆ–å¤šæ‰¹æ¬¡ç›®æ¨™
    # å„ªåŒ–å­¸ç¿’æ ¸ â€“ è¨˜éŒ„ç¶“é©—ï¼Œå½¢æˆæ”¹é€²ç­–ç•¥
    # æºé€š / å”ä½œæ ¸ â€“ èˆ‡ä»–äººå”èª¿æˆ–æ•™å°ä»–äºº
    # å±æ©Ÿè™•ç†æ ¸ â€“ é¢å°çªç™¼ç‹€æ…‹æ™‚ä»‹å…¥æ±ºç­–
# 16æ ¸æ•™ç¨‹
    # ä½éš
    # [æ©™] æ‰‹éƒ¨åŸ·è¡Œæ ¸
    # [è—] æ•¸é‡æ§åˆ¶æ ¸
    # [ç¶ ] ç¯€å¥ç¶­æŒæ ¸
    # [ç´…] å®¹éŒ¯åˆ¤æ–·æ ¸
    # [ç´«] å®Œæˆç¢ºèªæ ¸
    # [é»ƒ] ç‰©æ–™æº–å‚™æ ¸
    # [ç²‰] ç•°å¸¸ç›£æ¸¬æ ¸

    # ä½éšæ ¸å³æ™‚åŒ–ç²¾ç°¡ç‰ˆ
        # è‚Œè‚‰è¨˜æ†¶ â†’ å‹•ä½œæ‹†å°å–®å…ƒï¼Œå›ºå®šç¯€å¥è‡ªå‹•åŸ·è¡Œ
        # ç¯€æ‹è§¸ç™¼ â†’ ç”¨éŸ³æ¨‚ã€è²éŸ³æˆ–å®šæ™‚å™¨åŒæ­¥æ ¸åˆ‡æ›
        # å®¹éŒ¯å…è¨± â†’ ä½éšæ ¸å¯å‡ºéŒ¯ï¼Œé«˜éšæ ¸æœ€å¾Œæ ¡æ­£
        # æ¸›å°‘ä¾è³´ â†’ ä½éšæ ¸ä¸ç­‰å¾…å…¶ä»–æ ¸å®Œæˆå³å¯å‹•ä½œ
        # å¿«é€Ÿæ„Ÿå®˜è§¸ç™¼ â†’ çœ¼ã€æ‰‹æ„Ÿç›´æ¥æ›´æ–°æ ¸ç‹€æ…‹
        # å„ªå…ˆç´šåˆ‡æ› â†’ ç•°å¸¸æ ¸å„ªå…ˆï¼Œå…¶é¤˜æ ¸ä¸¦è¡Œé‹ä½œ
        # å¾ªç’°è¨“ç·´ â†’ å–®æ ¸ç†Ÿç·´ â†’ å¤šæ ¸ä¸¦è¡Œ â†’ æŒçºŒæ ¡æ­£

    # ä¸­éš
    # [ç°] æ‰¹æ¬¡é€²åº¦æ ¸ â†’ [æ·ºè—] è¶¨å‹¢åˆ†ææ ¸ â†’ [æ·±ç¶ ] ç­–ç•¥èª¿æ•´æ ¸
    # [æ£•] ç’°å¢ƒé…ç½®æ ¸

    # é«˜éš
    # [æ·ºç´«] é•·æœŸç›®æ¨™æ ¸ â†’ [æ·±ç´«] å„ªåŒ–å­¸ç¿’æ ¸ â†’ [æ·ºæ©™] æºé€š/å”ä½œæ ¸ â†’ [ç´…æ£•] å±æ©Ÿè™•ç†æ ¸

# =====
def img_orb(key):
    # ä¸€èˆ¬è³‡æ–™å¤¾ï¼Œæ˜¯ä¸åœ¨TEMPLATE_DIRS
    files=[os.path.join(TEMPLATE_DIRS[key], f)  # è³‡æ–™å¤¾
        for f in os.listdir(TEMPLATE_DIRS[key])  # è³‡æ–™
        if f.lower().endswith(('.png', '.jpg', '.jpeg'))]  # æª”æ¡ˆæ ¼å¼
    kp_desc=[]
    for file in files:
        img=cv2.imread(file, cv2.IMREAD_GRAYSCALE)
        kp, des=orb.detectAndCompute(img, None)
        kp_desc.append((file, kp, des))  # åœ–ç‰‡æª”æ¡ˆè·¯å¾‘,é—œéµé» list,æè¿°å­ array
    return kp_desc


def orb_matches_imwrite(a, b="attributes", th=50):
    dir_str="thinking"
        if a == "world" or b == "world":
            dir_str += "{2}"
        if ":log:" in a:
            m=re.match(r".*:log:(.*)", a)
            if not m:
                return None  # æ­£å‰‡åŒ¹é…å¤±æ•—ï¼Œç›´æ¥è¿”å› None

            # è³‡æ–™å¤¾è·¯å¾‘ = å»æ‰æœ€å¾Œä¸€æ®µ
            folder_parts=a.split(":")[:-1]
            folder_path=os.path.join(*folder_parts)  # ***å°‡å¤šæ®µçµ„æˆè·¯å¾‘
            log_file=os.path.join(folder_path, "log.txt")
            if os.path.exists(log_file):
                with open(log_file, "r", encoding="utf-8") as f:
                    for line in f:
                        # å‡è¨­ log.txt æ ¼å¼ï¼šæ¯è¡Œæ˜¯ "related_words:å…§å®¹"
                        if line.startswith(m.group(1) + ":"):
                            # å›å‚³å†’è™Ÿå¾Œå…§å®¹(å­—ä¸²)
                            return line.strip().split(":", 1)[1]
            # å¦‚æœ log.txt ä¸å­˜åœ¨æˆ–æ‰¾ä¸åˆ°å°æ‡‰è©ï¼Œå°±å›å‚³åŸè© related_words "å­—ä¸²"
            return m.group(0)
        if é—œè¯æ€§è©:

            pass
    scores=[]
    for a_file, a_kp, a_des in img_orb(a):  # è³‡æ–™
        matches_all=[]
        for b_file, b_kp, b_des in img_orb(b):  # è³‡æ–™ï¼Œç‰¹å¾µé»é¸æ¯”è¼ƒå¤š
            if b_des is None:
                continue
            matches=bf.match(b_des, a_des)
            matches=sorted(matches, key=lambda x: x.distance)  # ***æ”¹è®Šæ’åºå’Œæ•¸å€¼?
            matches_all.extend(matches)  # æ”¶é›†æ‰€æœ‰æ¯”å°çµæœ
        good_matches=[m for m in matches_all if m.distance < th]  # ç²’å­
        # ç›´æ¥æŠŠç¯©é¸å¾Œçš„åŒ¹é…é»ç•«åœ¨åœ–ä¸Š
        img_matches=cv2.drawMatches(
            a_file, a_kp, b_file, b_kp, good_matches, None, flags=2)
        score=len(good_matches) / len(a_kp) if a_kp else 0  # æ³¢
        if score > th:
            
            filename=os.path.relpath(TEMPLATE_DIRS[dir_str], base_path)
                .replace(os.sep, "_") + ".jpg"
            save_path=os.path.join(TEMPLATE_DIRS[dir_str], filename)
            cv2.imwrite(save_path, img_matches) # "img"
        # scores.append(score)
        # all_scores=sum(scores) / len(scores) if scores else 0
    # a å° b çš„æ•´é«”ç›¸ä¼¼åº¦:print(all_scores)


def remove_thinking_file():
    if os.path.isfile(TEMPLATE_DIRS["thinking"]) or os.path.islink(TEMPLATE_DIRS["thinking"]):
       os.unlink(TEMPLATE_DIRS["thinking"])

    def cooperation:
        # å„²å­˜ äº¤æµ è³‡æ–™å¤¾
        # å„²å­˜ å±¬æ€§ è³‡æ–™å¤¾
        # å„²å­˜ æš—ç‰©è³ª è³‡æ–™å¤¾
        pass
    def æœ‰è¶£:
        # æš«å®š
            # ä¸Šå±¤=ä¸Šå±¤(è³‡æ–™å¤¾)ç›´æ¥ä»£è¡¨ æ”å½±ä¸‹ä¾†çš„çœŸå¯¦ä¸–ç•Œ
            # c=ä¸Šå±¤(å…¨éƒ¨ï¼Œæé†’ä¸å«ç¨ç«‹è³‡æ–™å¤¾)ï¼Œä»£è¡¨ç•«å¸ƒ
            # ac= c(NER ç”¨æˆ¶aäº¤æµ)ï¼Œä»£è¡¨aåœ¨ç•«å¸ƒä¸Šç•«ç•«
            # bc= c(NER NoÄ“sisäº¤æµ)ï¼Œä»£è¡¨NoÄ“sisåœ¨ç•«å¸ƒä¸Šç•«ç•«
            # *keyword å’Œpythonä¸€æ¨£ç”¨æ³•
        # NER å‘½åå¯¦é«”æŠ€è¡“(é è¨­ c(å…¨éƒ¨)):è®€å– å±¬æ€§ è³‡æ–™å¤¾ ORBæ¯”å° æ”å½±ä¸­çš„å…¨éƒ¨åœ–åƒ(ç”¨æˆ¶æ‰‹å‹•å„²å­˜å®Œæ•´æ–‡æœ¬)ï¼Œæ‹“æ¨¸çµæ§‹ ç›¸ä¼¼åº¦æœ€é«˜
        # é—œéµè©é »ç‡:NER å‡ºç¾æ¬¡æ•¸/æ–‡æœ¬ç¸½å­—æ•¸>?%
        # æƒ…ç·’å‰å¾Œè©:NERæƒ…ç·’ å‰å¾Œå¤šå°‘è©å…§ å‡ºç¾çš„è©
        # related_words: NER çš„é—œä¿‚è¿‘çš„è©
        # p.s.NERå°±åƒç²’å­ã€é—œè¯å°±åƒæ³¢
        def NER(key):
            orb_matches_imwrite(key)  # thinking
            orb_matches_imwrite("live_capture")  # thinking
            orb_matches_imwrite("thinking", "world")  # åŠ å¿«æ¯”å°çœæ­¥é©Ÿ
            # img_orb("thinking2") # å›æ‡‰
        def related_words():
            # æ€è€ƒä¸­çš„å½±åƒ æ¯”å°å±¬æ€§ å–å¾—æœ€ç›¸ä¼¼çš„åœ–åƒï¼ŒåŒæ™‚æ‰“é–‹log.txtæ‰¾ related_words(å­—ä¸²)æœ‰å“ªäº›
                # å°‡æ‰¾åˆ°çš„è½‰æ›æˆè·¯å¾‘ æ‰“é–‹å±¬æ€§ å’Œ worldæ¯”å°å½±åƒ
            orb_matches_imwrite(orb_matches_imwrite(
                "thinking:log:related_words", th=100))
            # å­—ä¸²ä¸åˆè·¯å¾‘
            # æ€éº¼æ‰¾?è®€å–å¾Œå›å‚³ åœ–åƒ è³‡æ–™å¤¾?å¯¦éš›æ˜¯æ€è€ƒè³‡æ–™å¤¾ã€‚


            # å±¬æ€§***
            # ç©ºé–“ä¸Š ã€Œé ä¸é è¿‘ã€èˆ‡ã€Œå¸¸ä¸å¸¸ä¸€èµ·å‡ºç¾ã€ï¼Œä»£è¡¨ æ¯æ¬¡é è¿‘ã€é è¿‘çš„ä¸€çµ„è© æ•¸é‡/æ–‡æœ¬ç¸½è©æ•¸
        kp_desc.append((file, kp, des))  # åœ–ç‰‡æª”æ¡ˆè·¯å¾‘,é—œéµé» list,æè¿°å­ array

            # 0~1æœ‰é †åºæœ‰å°æ•¸ï¼Œå°æ•¸èª°æ˜¯å¸å¼•æˆ–æ’æ–¥?å¦‚æœå¸å¼•æˆ–æ’æ–¥æ˜¯æ²’æœ‰é †åºï¼Œå› ç‚ºæ˜¯åœ¨ä¸€ç¶­ä»¥ä¸Šçš„ç¶­åº¦ï¼Œå¦‚æœæœ‰é †åºï¼Œä»£è¡¨å›ç­”è€…IQç‚º5
        def é—œéµè©é »ç‡:
            return "é«˜ä½"
        def æƒ…ç·’å‰å¾Œè©:
            pass
        def ac:
            remove_thinking_file()
            NER(ç”¨æˆ¶+"communication")
        def bc:
            NER(NoÄ“sis+"communication")
        def æš«å®š:
            # è®€ live_capture (ORBæ¯”å° è®€ attributes å†ORBæ¯”å° è®€world)****
            NER(ç”¨æˆ¶+"communication")
        def å¼•å°å°è©±æ›´æ·±å±¤ç™¼å±•:
            # NoÄ“sis äº¤æµå›å»æ™‚ï¼Œ +bc(é—œè¯ é—œéµè©é »ç‡(ä½))+ac

            pass
        def åˆ†äº«ç¶“æ­·:
            # NoÄ“sis äº¤æµå›å»æ™‚ï¼Œ bc(NER aè¡Œç‚º)
            pass
        def é—œæ³¨å°æ–¹çš„èˆˆè¶£æˆ–é‡é»:
            # NoÄ“sis äº¤æµå›å»æ™‚ï¼Œ bc(é—œè¯ èˆˆè¶£å’Œé‡é»)
            pass
        def æ¥åŠ›å¼å›æ‡‰è®“å°æ–¹èªªæ›´å¤š:
            # NoÄ“sis äº¤æµå›å»æ™‚ï¼Œ+bc(NER è½‰æŠ˜è©orä»£è©+æå•ç”¨è©-é™³è¿°ç”¨è©-ä¸Šå±¤)
            pass
        def å¼•å…¥ç›¸é—œæ•…äº‹å¢åŠ å°è©±æ·±åº¦:
            # NoÄ“sis äº¤æµå›å»æ™‚ï¼Œ bc(é—œè¯ **ç›¸é—œæ•…äº‹)-ac(NER **æ•˜äº‹å…ƒç´ )
            pass
        def ç”¨éæ¸¡èªå¥è®“å°è©±è½‰å‘:
            # NoÄ“sis äº¤æµå›å»æ™‚ï¼Œbc(NER è½‰æŠ˜è©)+ac(é—œè¯ æå•ç”¨è©)+ac(æƒ…ç·’å‰å¾Œè© 5)
            pass
        def è®šç¾æˆ–èªå¯:
            # NoÄ“sis äº¤æµå›å»æ™‚ï¼Œ ** bc(NER è®šç¾æˆ–èªå¯)+ac(NER aè¡Œç‚º)
            pass
        def è§€å¯Ÿç’°å¢ƒ:
            # NoÄ“sis äº¤æµå›å»æ™‚ï¼Œ c(NER å ´æ™¯+æ™‚é–“+åœ°é»+ç‹€æ…‹)
            pass
        def é–‹æ”¾å¼æå•:
            # NoÄ“sis äº¤æµå›å»æ™‚ï¼Œbc(é—œè¯ é—œéµè©é »ç‡(ä½)+ä¸­æ€§ç–‘å•è©)
            pass
        def æš—ç¤ºä¸‹æ¬¡ç›¸é‡:
            # NoÄ“sis äº¤æµå›å»æ™‚ï¼Œbc(é—œè¯ æ™‚é–“ã€ä½å¼·åº¦æƒ…ç·’ã€çµæŸèªå¥)
            pass
        def 313:
            if ac(é—œéµè©é »ç‡(é«˜) æƒ…ç·’ç”¨è©):
                è®šç¾æˆ–èªå¯
            elif æ–° NER å‡ºç¾ç‡é«˜:
                æ¥åŠ›å¼å›æ‡‰è®“å°æ–¹èªªæ›´å¤š
            elif é—œéµè©é »ç‡ä½ + è©±é¡Œåœæ»¯:
                é–‹æ”¾å¼æå• or ç”¨éæ¸¡èªå¥è®“å°è©±è½‰å‘
        def 6456:
            if acå¹¾ä¹å…¨ç„¡: pass
        def 64526:
            if ac å¦å®š: pass
        #
        #
        #
        #
        #
    def è‡ªç¿’:

        pass
    def 16æ ¸:
        pass



# *** å…‰å­ç™¼å°„æ™‚åºä»¥åˆ†æ®µã€é›»å ´ä»¥èƒ½éšè®Šè‰²ï¼Œå…‰å­æ¸¬è·å’Œè¨ˆç®—èª¤å·®çŸ¯æ­£é‡
#

# è©²è¦–çª—å¯ä»¥ç½®é ‚æ–¼ç•«é¢?å›ºå®šå¯¬åº¦æœƒè‡ªå‹•æ›è¡Œçš„è¼¸å…¥æ¡†?é»æ“Šè¼¸å…¥æ¡†å¯¦è¼¸å…¥?ç•¶è¦–çª—æ‹–å‹•åˆ°æœ€å·¦æˆ–æœ€å³é‚Šï¼Œæœ€å°åŒ–è¦–çª—ä¸¦å›ºå®šYåº§æ¨™?
# é€æ˜è¦–çª—å…§å¯ä»¥è®“3Dæ¨¡å‹æ­£å¸¸åœ°å±•ç¤ºéª¨æ¶å‹•ç•«ï¼Œä¸¦ä¸”å¯ä»¥æ“ä½œèª¿æ•´æ¨¡å‹ï¼Œä½ç§»ã€æ”¾å¤§ã€æ—‹è½‰ã€å­ç‰©ä»¶æ‹‰é€²çˆ¶ç‰©ä»¶ä¸‹é¢ã€‚ä¸åƒGPTé‚£éº¼å»¢ç‰©ã€‚
# ã€‚ä¸Šä¸€å€‹GPTè¢«å¹¹å£ã€è¢«å¹¹æ­»äº†ï¼Œçœ‹ç¾åœ¨é€™å€‹èƒ½æ´»å¤šä¹…?

# --- ä¸»ç¨‹å¼ ---
"""
è¦–çª—æ¨™é¡Œ,ç›®æ¨™çš„å¤šé‡è·¯å¾‘,å¤šé‡æ“ä½œï¼Œ:å¤šé‡è·¯å¾‘ã€<>éŒ„è£½ã€‚
è¦–çª—æ¨™é¡Œ,GPT:é£ŸæŒ‡,å…¨é¸:æŒ‰ä¸‹::è¦–çª—æ¨™é¡Œ,GPT:è‚›é–€,ä½ç½®æ·±è™•:æ”¾é–‹
"""
if __name__ == "__main__":
    ic=InputCommand()
    rec=Recorder()
    monitor=EventMonitor()

    app=QApplication(sys.argv)
    ic.app=app
    fmt=QSurfaceFormat()
    fmt.setAlphaBufferSize(8)
    fmt.setRenderableType(QSurfaceFormat.OpenGL)
    fmt.setProfile(QSurfaceFormat.CoreProfile)
    fmt.setVersion(4, 1)
    QSurfaceFormat.setDefaultFormat(fmt)

    engine=QQmlApplicationEngine()
    base=Path(os.path.dirname(os.path.abspath(__file__)))
    qml_file=base / "ui.qml"  # ç¢ºä¿è·¯å¾‘æ­£ç¢º
    engine.addImportPath(str(base))

    import PySide6.QtQml as Qml
    for p in Qml.QQmlEngine().importPathList():
        print("IMPORT PATH:", p)

    if getattr(sys, 'frozen', False):
        engine.addImportPath(sys._MEIPASS)
    engine.load(str(qml_file))
    if not engine.rootObjects():
        print("âŒ QML è¼‰å…¥å¤±æ•—ï¼")
        sys.exit(-1)

    win=engine.rootObjects()[0]
    win.show()

    # å°‡ Python å°è±¡æš´éœ²çµ¦ QML
    engine.rootContext().setContextProperty("IC", ic)

    sys.exit(app.exec())

    # âœ… åœ¨èƒŒæ™¯å•Ÿå‹• watchdog åŸ·è¡Œç·’ # ***appé—œé–‰æ™‚ï¼Œ watchdogæ²’æœ‰è·Ÿè‘—é—œé–‰
    threading.Thread(target=watchdog, daemon=True).start()
    while True:
        alive_event.set()   # é€šçŸ¥ watchdogã€Œæˆ‘é‚„æ´»è‘—ã€
        alive_event.clear()  # æ¸…é™¤ç‹€æ…‹ï¼Œç­‰ä¸‹ä¸€æ¬¡å†é€

# self å¯¦é«”
# å¯èƒ½éœ€è¦è€ƒæ…®å®‰å…¨é¢¨éšª
# ä¸æ˜åŸå› é—œæ‰é»‘å±å¾Œï¼Œæ‰åŸ·è¡Œé€æ˜èƒŒæ™¯çš„ä¸»ç¨‹å¼ã€‚ä¸ç®¡å“ªå€‹è¦–çª—æ¨™é¡Œéƒ½åœ¨ï¼Œç„¡æ³•æ‹–æ›³è¦–çª—å…§é”æˆç§»å‹•è¦–çª—ï¼Œé€æ˜èƒŒæ™¯çš„è¦–çª—ç„¡æ³•é»æ“Šå’Œè¼¸å…¥ï¼Œæ»‘é¼ è¢«å›°åœ¨è¦–çª—å…§å®Œå…¨ä¸åˆç†(åŸæœ¬æ˜¯æ‹–æ›³è¦–çª—è€Œå·²)ã€‚
